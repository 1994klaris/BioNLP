### 26/3

* First meeting with our supervisors
* Read the paper "SCIBERT: A Pretrained Language Model for Scientific Text" (https://arxiv.org/pdf/1903.10676.pdf)
* Read about SciBert (https://github.com/allenai/scibert)
* Watched a quick video about BERT: "BERT Neural Network - EXPLAINED!" (https://www.youtube.com/watch?v=xI0HHN5XKDo) 
* Cloned the BioNLP repo

### 1/4

* Tried to set up the environment, had issues with too little memory on Windows and a not compatible GPU with Cuda on Mac

### 6/4

* Meeting, got recommended to try Google Colab

### 13/4

* Meeting
* Set up logbook and the report 

### 19/4: 

* We got the environment to work and trained the SciBert on the Chemprot corpus using Google Colab
* Watched "Lecture 7 â€“ Relation Extraction | Stanford CS224U: Natural Language Understanding | Spring 2019" (https://www.youtube.com/watch?v=pO3Jsr31s_Q)
