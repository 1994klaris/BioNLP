{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare tokenizers\n",
    "Aim: Comparing different tokenizers on biomedical abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created by Sonja Aits, Lund University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further reading:\n",
    "    \n",
    "https://lhncbc.nlm.nih.gov/publication/lhncbc-tr-2006-003\n",
    "\n",
    "https://www.aclweb.org/anthology/W15-2605/\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4749772/\n",
    "    \n",
    "https://en.wikipedia.org/wiki/Gene_nomenclature\n",
    "\n",
    "https://en.wikipedia.org/wiki/Chemical_nomenclature\n",
    "\n",
    "https://www.genenames.org/about/guidelines/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downloaded cell death journal abstracts from following pubmed search (using send function and abstract option): (Cell Death Differ[journal]) OR (Cell Death Discov[journal]) OR (Cell Death Dis[journal]) OR Apoptosis[journal] Save in file celldeathabstracts_20191230.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first abstract saved as abstract1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. cell death differ. 2019 dec 20. doi: 10.1038/s41418-019-0483-6. [epub ahead of\n",
      "print]\n",
      "\n",
      "hnrnp f/h associate with hterc and telomerase holoenzyme to modulate telomerase\n",
      "function and promote cell proliferation.\n",
      "\n",
      "xu c(1), xie n(2), su y(1), sun z(1), liang y(1), zhang n(1), liu d(1), jia s(3),\n",
      "xing x(3), han l(1), li g(1), tong t(1), chen j(4).\n",
      "\n",
      "author information: \n",
      "(1)peking university research center on aging, beijing key laboratory of protein \n",
      "posttranslational modifications and cell function, department of biochemistry and\n",
      "molecular biology, department of integration of chinese and western medicine,\n",
      "school of basic medical science, peking university, beijing, 100191, china.\n",
      "(2)department of physiology and pathophysiology, school of basic medical science,\n",
      "peking university, beijing, 100191, china.\n",
      "(3)department of molecular diagnostics, key laboratory of carcinogenesis and\n",
      "translational research (ministry of education), peking university cancer hospital\n",
      "& institute, beijing, 100142, china.\n",
      "(4)peking university research center on aging, beijing key laboratory of protein \n",
      "posttranslational modifications and cell function, department of biochemistry and\n",
      "molecular biology, department of integration of chinese and western medicine,\n",
      "school of basic medical science, peking university, beijing, 100191, china.\n",
      "cjbiochem@bjmu.edu.cn.\n",
      "\n",
      "human telomerase rna component hterc comprises multiple motifs that contribute to\n",
      "hterc biogenesis, holoenzyme activity, and enzyme recruitment to telomeres. hterc\n",
      "contains several guanine tracts (g-tracts) at its 5'-end, but its associated\n",
      "proteins and potential roles in telomerase function are still poorly understood. \n",
      "the heterogeneous nuclear ribonucleoproteins f, h1, and h2 (hnrnp f/h) are\n",
      "splicing factors that preferentially bind to poly(g)-rich sequences rna. here, we\n",
      "demonstrate that hnrnp f/h associate with both hterc and telomerase holoenzyme to\n",
      "regulate telomerase activity. we reveal hnrnp f/h bind to the 5'-end region of\n",
      "hterc in vitro and in vivo, and identify the first three g-tracts of hterc and\n",
      "qrrm1 domain of hnrnp f/h are required for their interaction. furthermore, hnrnp \n",
      "f/h also directly interact with telomerase holoenzyme. functionally, we show that\n",
      "hnrnp f/h plays important roles in modulating telomerase activity and telomere\n",
      "length. moreover, hnrnp f/h deletion greatly impair cancer and stem cell\n",
      "proliferation, and induce stem cell senescence, while hnrnp f/h overexpression\n",
      "delay stem cell senescence. collectively, our findings unveil a novel role of\n",
      "hnrnp f/h as the binding partners of hterc and telomerase holoenzyme to regulate \n",
      "telomerase function.\n",
      "\n",
      "doi: 10.1038/s41418-019-0483-6 \n",
      "pmid: 31863069 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "abstract = open('abstract1.txt', encoding=\"utf8\").read()\n",
    "abstract = abstract.lower()\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_abstracts = open('celldeathabstracts_20191230.txt', encoding=\"utf8\").read()\n",
    "cd_abstracts = cd_abstracts.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tricky examples of biomedical text inspired by articles above and compiled by me (stored at D:/Lab/Data/tokenization.txt)\n",
    "\n",
    "examples = \"\"\"Compound words\n",
    "Hydrogen peroxide causes cell death\n",
    "Cell death is caused by hydrogen peroxide\n",
    "UV radiation kills cancer cells\n",
    "\n",
    "Hyphenated compound words\n",
    "co-localization\n",
    "Co-localization\n",
    "wild-type \n",
    "Wild-type \n",
    "TLR-4 \n",
    "X-ray\n",
    "\n",
    "Slashes\n",
    "downregulation/mutation \n",
    "Downregulation/mutation \n",
    "Downregulation/Mutation \n",
    "P53/73 \n",
    "p53/73 \n",
    "Omi/HtrA2 \n",
    "HER2/Neu\n",
    "mg/ml\n",
    "\n",
    "&\n",
    "Material&Methods\n",
    "material&methods\n",
    "\n",
    "‘ ' \"\n",
    "Parkinson’s\n",
    "can’t \n",
    "wouldn’t \n",
    "haven’t \n",
    "hadn’t \n",
    "shouldn’t \n",
    "cells’ circumference \n",
    "‘localization’ \n",
    "Parkinson's \n",
    "can't \n",
    "wouldn't \n",
    "haven't \n",
    "hadn't \n",
    "shouldn't \n",
    "cells' \n",
    "'localization' \n",
    "\"localization\"\n",
    "\n",
    "Non-alphanumerical symbols\n",
    "TNF-α \n",
    "\n",
    "Brackets\n",
    "(cells)\n",
    "[cells]\n",
    "{cells}\n",
    "<cells>\n",
    "(Cells)\n",
    "[Cells]\n",
    "{Cells}\n",
    "<Cells>\n",
    "(GAPDH)\n",
    "[GAPDH]\n",
    "{GAPDH}\n",
    "<GAPDH>\n",
    "(cells)\n",
    "(cells) \n",
    "A)\n",
    "2)\n",
    "\n",
    "Combined letters and punctuation\n",
    "A.\n",
    "e.g.\n",
    "e.g.,\n",
    "i.e.\n",
    "p.o.\n",
    "The cell is dead. Therefore, we \n",
    "\n",
    "Combined letters and numbers\n",
    "O2\n",
    "30th\n",
    "LAMP2\n",
    "log2\n",
    "2nd \n",
    "\n",
    "Numbers with blanks\n",
    "4 000 453\n",
    "\n",
    "Combined numbers and punctuation\n",
    "3,000,000\n",
    "1/2\n",
    "76%\n",
    "1.4\n",
    "1-20\n",
    "1)\n",
    "1.\n",
    "\n",
    "Mathematical operators\n",
    "5*4\n",
    "5x4\n",
    "5⋅4\n",
    "56/8\n",
    "5+70=75\n",
    "5 + 70 = 75\n",
    "5-4\n",
    "-40\n",
    "6.65×10^−34\n",
    "6.65 × 10^−34\n",
    "20+/-5\n",
    "5.6-7.5%\n",
    "7^3\n",
    "5˃3\n",
    "5˃=x\n",
    "\n",
    "Units\n",
    "20 mg/ml\n",
    "20 mg/mL\n",
    "20 µl/ml\n",
    "20 µg/mol\n",
    "20 m/s\n",
    "20 Gy\n",
    "20Gy\n",
    "20 °C\n",
    "20°C\n",
    "20mmol\n",
    "20 mg/mg/h\n",
    "\n",
    "Nucleotide sequences\n",
    "5’-TTAC-3’\n",
    "GGGCAAATT\n",
    "GGGCAAAUU \n",
    "\n",
    "Gene, RNA, Protein names\n",
    "miR-643\n",
    "LAMP2\n",
    "Gal1-3\n",
    "leuAum\n",
    "leuAcs\n",
    "leuA+\n",
    "leuA−\n",
    "ΔleuA\n",
    "leuA-lacZ\n",
    "leuA:lacZ\n",
    "leuA::Tn10\n",
    "ΩleuA\n",
    "ΔleuA::nptII(KanR)\n",
    "mTOR\n",
    "\n",
    "Chemicals\n",
    "HC9H7O4\n",
    "2-acetyloxybenzoic acid\n",
    "InChI=1S/C9H8O4/c1-6(10)13-8-5-3-2-4-7(8)9(11)12/h2-5H,1H3,(H,11,12)\n",
    "BSYNRYMUTXBXSQ-UHFFFAOYSA-N\n",
    "CC(=O)OC1=CC=CC=C1C(=O)O\n",
    "Ca2+\n",
    "\n",
    "Identifiers\n",
    "50-78-2\n",
    "GAL3_HUMAN\n",
    "P2446246\n",
    "NM_235235\n",
    "\n",
    "Complex combinations\n",
    "LAMP1/2\n",
    "LAMP1-2\n",
    "(LAMP1-2)\n",
    "(see below (Fig.1))\n",
    "A-B)\n",
    "\n",
    "\n",
    "Hypertext \n",
    "&lt\n",
    "&quot\n",
    "\n",
    "Links\n",
    "http://www.lu.se\n",
    "https://ai-lu.com/gst.txt \n",
    "ftp://as.li.de\n",
    "https://doi.org/10.1109/5.771073\n",
    "\n",
    "Emails\n",
    "sdfsag@gmail.com\n",
    "asg.smg@lu.se \n",
    "\n",
    "Times and dates\n",
    "7d\n",
    "7 d\n",
    "00:30 min\n",
    "30min\n",
    "5h\n",
    "5 hours\n",
    "5 weeks\n",
    "5 s\n",
    "5 sec\n",
    "5 seconds\n",
    "2019-09-01\n",
    "1 Sept 2019\n",
    "1st of September 2019\n",
    "Sept 1, 2019\n",
    "Sept 1 2019\n",
    "1.9.2019\n",
    "01.09.2019\n",
    "\n",
    "Abbreviations\n",
    "CytoC\n",
    "hGal3\n",
    "h-Gal13\n",
    "Cyto-c\n",
    "MERS\n",
    "CD4+\n",
    "CD4+\n",
    "C. elegans growth was inhibited\n",
    "\"\"\"\n",
    "\n",
    "#how are formatting differences preserved? superscript, subscript, italics, bold, font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\n",
      "407\n",
      "3921337\n",
      "\n",
      "['1', 'cell', 'death', 'differ', '2019', 'dec', '20', 'doi', '10', '1038', 's41418', '019', '0483', '6', 'epub', 'ahead', 'of', 'print', 'hnrnp', 'f', 'h', 'associate', 'with', 'hterc', 'and', 'telomerase', 'holoenzyme', 'to', 'modulate', 'telomerase', 'function', 'and', 'promote', 'cell', 'proliferation', 'xu', 'c', '1', 'xie', 'n']\n",
      "\n",
      "['Compound', 'words', 'Hydrogen', 'peroxide', 'causes', 'cell', 'death', 'Cell', 'death', 'is', 'caused', 'by', 'hydrogen', 'peroxide', 'UV', 'radiation', 'kills', 'cancer', 'cells', 'Hyphenated', 'compound', 'words', 'co', 'localization', 'Co', 'localization', 'wild', 'type', 'Wild', 'type', 'TLR', '4', 'X', 'ray', 'Slashes', 'downregulation', 'mutation', 'Downregulation', 'mutation', 'Downregulation', 'Mutation', 'P53', '73', 'p53', '73', 'Omi', 'HtrA2', 'HER2', 'Neu', 'mg', 'ml', 'Material', 'Methods', 'material', 'methods', 'Parkinson', 's', 'can', 't', 'wouldn', 't', 'haven', 't', 'hadn', 't', 'shouldn', 't', 'cells', 'circumference', 'localization', 'Parkinson', 's', 'can', 't', 'wouldn', 't', 'haven', 't', 'hadn', 't', 'shouldn', 't', 'cells', 'localization', 'localization', 'Non', 'alphanumerical', 'symbols', 'TNF', 'α', 'Brackets', 'cells', 'cells', 'cells', 'cells', 'Cells', 'Cells', 'Cells', 'Cells', 'GAPDH', 'GAPDH', 'GAPDH', 'GAPDH', 'cells', 'cells', 'A', '2', 'Combined', 'letters', 'and', 'punctuation', 'A', 'e', 'g', 'e', 'g', 'i', 'e', 'p', 'o', 'The', 'cell', 'is', 'dead', 'Therefore', 'we', 'Combined', 'letters', 'and', 'numbers', 'O2', '30th', 'LAMP2', 'log2', '2nd', 'Numbers', 'with', 'blanks', '4', '000', '453', 'Combined', 'numbers', 'and', 'punctuation', '3', '000', '000', '1', '2', '76', '1', '4', '1', '20', '1', '1', 'Mathematical', 'operators', '5', '4', '5x4', '5', '4', '56', '8', '5', '70', '75', '5', '70', '75', '5', '4', '40', '6', '65', '10', '34', '6', '65', '10', '34', '20', '5', '5', '6', '7', '5', '7', '3', '5', '3', '5', 'x', 'Units', '20', 'mg', 'ml', '20', 'mg', 'mL', '20', 'µl', 'ml', '20', 'µg', 'mol', '20', 'm', 's', '20', 'Gy', '20Gy', '20', 'C', '20', 'C', '20mmol', '20', 'mg', 'mg', 'h', 'Nucleotide', 'sequences', '5', 'TTAC', '3', 'GGGCAAATT', 'GGGCAAAUU', 'Gene', 'RNA', 'Protein', 'names', 'miR', '643', 'LAMP2', 'Gal1', '3', 'leuAum', 'leuAcs', 'leuA', 'leuA', 'ΔleuA', 'leuA', 'lacZ', 'leuA', 'lacZ', 'leuA', 'Tn10', 'ΩleuA', 'ΔleuA', 'nptII', 'KanR', 'mTOR', 'Chemicals', 'HC9H7O4', '2', 'acetyloxybenzoic', 'acid', 'InChI', '1S', 'C9H8O4', 'c1', '6', '10', '13', '8', '5', '3', '2', '4', '7', '8', '9', '11', '12', 'h2', '5H', '1H3', 'H', '11', '12', 'BSYNRYMUTXBXSQ', 'UHFFFAOYSA', 'N', 'CC', 'O', 'OC1', 'CC', 'CC', 'C1C', 'O', 'O', 'Ca2', 'Identifiers', '50', '78', '2', 'GAL3_HUMAN', 'P2446246', 'NM_235235', 'Complex', 'combinations', 'LAMP1', '2', 'LAMP1', '2', 'LAMP1', '2', 'see', 'below', 'Fig', '1', 'A', 'B', 'Hypertext', 'lt', 'quot', 'Links', 'http', 'www', 'lu', 'se', 'https', 'ai', 'lu', 'com', 'gst', 'txt', 'ftp', 'as', 'li', 'de', 'https', 'doi', 'org', '10', '1109', '5', '771073', 'Emails', 'sdfsag', 'gmail', 'com', 'asg', 'smg', 'lu', 'se', 'Times', 'and', 'dates', '7d', '7', 'd', '00', '30', 'min', '30min', '5h', '5', 'hours', '5', 'weeks', '5', 's', '5', 'sec', '5', 'seconds', '2019', '09', '01', '1', 'Sept', '2019', '1st', 'of', 'September', '2019', 'Sept', '1', '2019', 'Sept', '1', '2019', '1', '9', '2019', '01', '09', '2019', 'Abbreviations', 'CytoC', 'hGal3', 'h', 'Gal13', 'Cyto', 'c', 'MERS', 'CD4', 'CD4', 'C', 'elegans', 'growth', 'was', 'inhibited']\n",
      "\n",
      "[('of', 170984), ('the', 109680), ('and', 106297), ('in', 86485), ('1', 64523), ('a', 43092), ('to', 42754), ('cell', 39921), ('2', 35152), ('that', 31925), ('for', 31108), ('cells', 28950), ('by', 26679), ('10', 26591), ('university', 26235), ('apoptosis', 23973), ('death', 23056), ('3', 22845), ('is', 22787), ('doi', 22155), ('with', 20320), ('we', 18401), ('1038', 18388), ('department', 17964), ('cancer', 15933), ('induced', 14968), ('as', 14632), ('4', 14431), ('china', 13894), ('expression', 13229), ('was', 12946), ('pmid', 12668), ('information', 12360), ('author', 12230), ('5', 11797), ('medical', 10588), ('this', 10284), ('s', 10244), ('indexed', 10198), ('medline', 10198)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#Placing r or R before string creates Raw-string. Raw-strings do not process escape sequences (\\n, \\b, etc.) and are commonly used for Regex patterns, which often contain a lot of \\ characters \n",
    "#\\w+ matches one or several characters of a-z, A-Z, 0-9, _\n",
    "tokens_abstract = tokenizer.tokenize(abstract)\n",
    "tokens_examples = tokenizer.tokenize(examples)\n",
    "tokens_cd_abstracts = tokenizer.tokenize(cd_abstracts)\n",
    "counts_cd_abstracts = FreqDist(tokens_cd_abstracts)\n",
    "\n",
    "\n",
    "print(len(tokens_abstract))\n",
    "print(len(tokens_examples))\n",
    "print(len(tokens_cd_abstracts))\n",
    "print()\n",
    "print(tokens_abstract[:40])\n",
    "print()\n",
    "print(tokens_examples)\n",
    "print()\n",
    "print(counts_cd_abstracts.most_common(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk RegexpTokenizer (gaps mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367\n",
      "270\n",
      "3465883\n",
      "\n",
      "['1.', 'cell', 'death', 'differ.', '2019', 'dec', '20.', 'doi:', '10.1038/s41418-019-0483-6.', '[epub', 'ahead', 'of', 'print]', 'hnrnp', 'f/h', 'associate', 'with', 'hterc', 'and', 'telomerase', 'holoenzyme', 'to', 'modulate', 'telomerase', 'function', 'and', 'promote', 'cell', 'proliferation.', 'xu', 'c(1),', 'xie', 'n(2),', 'su', 'y(1),', 'sun', 'z(1),', 'liang', 'y(1),', 'zhang']\n",
      "\n",
      "['Compound', 'words', 'Hydrogen', 'peroxide', 'causes', 'cell', 'death', 'Cell', 'death', 'is', 'caused', 'by', 'hydrogen', 'peroxide', 'UV', 'radiation', 'kills', 'cancer', 'cells', 'Hyphenated', 'compound', 'words', 'co-localization', 'Co-localization', 'wild-type', 'Wild-type', 'TLR-4', 'X-ray', 'Slashes', 'downregulation/mutation', 'Downregulation/mutation', 'Downregulation/Mutation', 'P53/73', 'p53/73', 'Omi/HtrA2', 'HER2/Neu', 'mg/ml', '&', 'Material&Methods', 'material&methods', '‘', \"'\", '\"', 'Parkinson’s', 'can’t', 'wouldn’t', 'haven’t', 'hadn’t', 'shouldn’t', 'cells’', 'circumference', '‘localization’', \"Parkinson's\", \"can't\", \"wouldn't\", \"haven't\", \"hadn't\", \"shouldn't\", \"cells'\", \"'localization'\", '\"localization\"', 'Non-alphanumerical', 'symbols', 'TNF-α', 'Brackets', '(cells)', '[cells]', '{cells}', '<cells>', '(Cells)', '[Cells]', '{Cells}', '<Cells>', '(GAPDH)', '[GAPDH]', '{GAPDH}', '<GAPDH>', '(cells)', '(cells)', 'A)', '2)', 'Combined', 'letters', 'and', 'punctuation', 'A.', 'e.g.', 'e.g.,', 'i.e.', 'p.o.', 'The', 'cell', 'is', 'dead.', 'Therefore,', 'we', 'Combined', 'letters', 'and', 'numbers', 'O2', '30th', 'LAMP2', 'log2', '2nd', 'Numbers', 'with', 'blanks', '4', '000', '453', 'Combined', 'numbers', 'and', 'punctuation', '3,000,000', '1/2', '76%', '1.4', '1-20', '1)', '1.', 'Mathematical', 'operators', '5*4', '5x4', '5⋅4', '56/8', '5+70=75', '5', '+', '70', '=', '75', '5-4', '-40', '6.65×10^−34', '6.65', '×', '10^−34', '20+/-5', '5.6-7.5%', '7^3', '5˃3', '5˃=x', 'Units', '20', 'mg/ml', '20', 'mg/mL', '20', 'µl/ml', '20', 'µg/mol', '20', 'm/s', '20', 'Gy', '20Gy', '20', '°C', '20°C', '20mmol', '20', 'mg/mg/h', 'Nucleotide', 'sequences', '5’-TTAC-3’', 'GGGCAAATT', 'GGGCAAAUU', 'Gene,', 'RNA,', 'Protein', 'names', 'miR-643', 'LAMP2', 'Gal1-3', 'leuAum', 'leuAcs', 'leuA+', 'leuA−', 'ΔleuA', 'leuA-lacZ', 'leuA:lacZ', 'leuA::Tn10', 'ΩleuA', 'ΔleuA::nptII(KanR)', 'mTOR', 'Chemicals', 'HC9H7O4', '2-acetyloxybenzoic', 'acid', 'InChI=1S/C9H8O4/c1-6(10)13-8-5-3-2-4-7(8)9(11)12/h2-5H,1H3,(H,11,12)', 'BSYNRYMUTXBXSQ-UHFFFAOYSA-N', 'CC(=O)OC1=CC=CC=C1C(=O)O', 'Ca2+', 'Identifiers', '50-78-2', 'GAL3_HUMAN', 'P2446246', 'NM_235235', 'Complex', 'combinations', 'LAMP1/2', 'LAMP1-2', '(LAMP1-2)', '(see', 'below', '(Fig.1))', 'A-B)', 'Hypertext', '&lt', '&quot', 'Links', 'http://www.lu.se', 'https://ai-lu.com/gst.txt', 'ftp://as.li.de', 'https://doi.org/10.1109/5.771073', 'Emails', 'sdfsag@gmail.com', 'asg.smg@lu.se', 'Times', 'and', 'dates', '7d', '7', 'd', '00:30', 'min', '30min', '5h', '5', 'hours', '5', 'weeks', '5', 's', '5', 'sec', '5', 'seconds', '2019-09-01', '1', 'Sept', '2019', '1st', 'of', 'September', '2019', 'Sept', '1,', '2019', 'Sept', '1', '2019', '1.9.2019', '01.09.2019', 'Abbreviations', 'CytoC', 'hGal3', 'h-Gal13', 'Cyto-c', 'MERS', 'CD4+', 'CD4+', 'C.', 'elegans', 'growth', 'was', 'inhibited']\n",
      "\n",
      "[('of', 170667), ('the', 108686), ('and', 105547), ('in', 86184), ('to', 42451), ('a', 36911), ('cell', 36789), ('that', 31607), ('for', 31079), ('by', 26588), ('is', 22630), ('doi:', 22132), ('with', 20286), ('death', 19208), ('we', 18367), ('cells', 18173), ('as', 14441), ('apoptosis', 14025), ('university', 13582), ('was', 12931), ('cancer', 12911), ('pmid:', 12668), ('china.', 12428), ('author', 12210), ('information:', 12167), ('university,', 11998), ('expression', 11058), ('medical', 10357), ('[indexed', 10198), ('medline]', 10198), ('this', 10083), ('an', 9310), ('on', 8623), ('medicine,', 8265), ('are', 8085), ('protein', 8034), ('or', 7941), ('pmcid:', 7874), ('these', 7704), ('which', 7575)]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer('\\s+', gaps=True) #splits on the indicated pattern\n",
    "tokens_abstract = tokenizer.tokenize(abstract)\n",
    "tokens_examples = tokenizer.tokenize(examples)\n",
    "tokens_cd_abstracts = tokenizer.tokenize(cd_abstracts)\n",
    "counts_cd_abstracts = FreqDist(tokens_cd_abstracts)\n",
    "\n",
    "\n",
    "print(len(tokens_abstract))\n",
    "print(len(tokens_examples))\n",
    "print(len(tokens_cd_abstracts))\n",
    "print()\n",
    "print(tokens_abstract[:40])\n",
    "print()\n",
    "print(tokens_examples)\n",
    "print()\n",
    "print(counts_cd_abstracts.most_common(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n",
      "399\n",
      "4650661\n",
      "\n",
      "['1.', 'cell', 'death', 'differ', '.', '2019', 'dec', '20.', 'doi', ':', '10.1038/s41418-019-0483-6', '.', '[', 'epub', 'ahead', 'of', 'print', ']', 'hnrnp', 'f/h', 'associate', 'with', 'hterc', 'and', 'telomerase', 'holoenzyme', 'to', 'modulate', 'telomerase', 'function', 'and', 'promote', 'cell', 'proliferation', '.', 'xu', 'c', '(', '1', ')']\n",
      "\n",
      "['Compound', 'words', 'Hydrogen', 'peroxide', 'causes', 'cell', 'death', 'Cell', 'death', 'is', 'caused', 'by', 'hydrogen', 'peroxide', 'UV', 'radiation', 'kills', 'cancer', 'cells', 'Hyphenated', 'compound', 'words', 'co-localization', 'Co-localization', 'wild-type', 'Wild-type', 'TLR-4', 'X-ray', 'Slashes', 'downregulation/mutation', 'Downregulation/mutation', 'Downregulation/Mutation', 'P53/73', 'p53/73', 'Omi/HtrA2', 'HER2/Neu', 'mg/ml', '&', 'Material', '&', 'Methods', 'material', '&', 'methods', '‘', \"'\", '``', 'Parkinson', '’', 's', 'can', '’', 't', 'wouldn', '’', 't', 'haven', '’', 't', 'hadn', '’', 't', 'shouldn', '’', 't', 'cells', '’', 'circumference', '‘', 'localization', '’', 'Parkinson', \"'s\", 'ca', \"n't\", 'would', \"n't\", 'have', \"n't\", 'had', \"n't\", 'should', \"n't\", 'cells', \"'\", \"'localization\", \"'\", \"''\", 'localization', \"''\", 'Non-alphanumerical', 'symbols', 'TNF-α', 'Brackets', '(', 'cells', ')', '[', 'cells', ']', '{', 'cells', '}', '<', 'cells', '>', '(', 'Cells', ')', '[', 'Cells', ']', '{', 'Cells', '}', '<', 'Cells', '>', '(', 'GAPDH', ')', '[', 'GAPDH', ']', '{', 'GAPDH', '}', '<', 'GAPDH', '>', '(', 'cells', ')', '(', 'cells', ')', 'A', ')', '2', ')', 'Combined', 'letters', 'and', 'punctuation', 'A.', 'e.g', '.', 'e.g.', ',', 'i.e', '.', 'p.o', '.', 'The', 'cell', 'is', 'dead', '.', 'Therefore', ',', 'we', 'Combined', 'letters', 'and', 'numbers', 'O2', '30th', 'LAMP2', 'log2', '2nd', 'Numbers', 'with', 'blanks', '4', '000', '453', 'Combined', 'numbers', 'and', 'punctuation', '3,000,000', '1/2', '76', '%', '1.4', '1-20', '1', ')', '1', '.', 'Mathematical', 'operators', '5*4', '5x4', '5⋅4', '56/8', '5+70=75', '5', '+', '70', '=', '75', '5-4', '-40', '6.65×10^−34', '6.65', '×', '10^−34', '20+/-5', '5.6-7.5', '%', '7^3', '5˃3', '5˃=x', 'Units', '20', 'mg/ml', '20', 'mg/mL', '20', 'µl/ml', '20', 'µg/mol', '20', 'm/s', '20', 'Gy', '20Gy', '20', '°C', '20°C', '20mmol', '20', 'mg/mg/h', 'Nucleotide', 'sequences', '5', '’', '-TTAC-3', '’', 'GGGCAAATT', 'GGGCAAAUU', 'Gene', ',', 'RNA', ',', 'Protein', 'names', 'miR-643', 'LAMP2', 'Gal1-3', 'leuAum', 'leuAcs', 'leuA+', 'leuA−', 'ΔleuA', 'leuA-lacZ', 'leuA', ':', 'lacZ', 'leuA', ':', ':Tn10', 'ΩleuA', 'ΔleuA', ':', ':nptII', '(', 'KanR', ')', 'mTOR', 'Chemicals', 'HC9H7O4', '2-acetyloxybenzoic', 'acid', 'InChI=1S/C9H8O4/c1-6', '(', '10', ')', '13-8-5-3-2-4-7', '(', '8', ')', '9', '(', '11', ')', '12/h2-5H,1H3', ',', '(', 'H,11,12', ')', 'BSYNRYMUTXBXSQ-UHFFFAOYSA-N', 'CC', '(', '=O', ')', 'OC1=CC=CC=C1C', '(', '=O', ')', 'O', 'Ca2+', 'Identifiers', '50-78-2', 'GAL3_HUMAN', 'P2446246', 'NM_235235', 'Complex', 'combinations', 'LAMP1/2', 'LAMP1-2', '(', 'LAMP1-2', ')', '(', 'see', 'below', '(', 'Fig.1', ')', ')', 'A-B', ')', 'Hypertext', '&', 'lt', '&', 'quot', 'Links', 'http', ':', '//www.lu.se', 'https', ':', '//ai-lu.com/gst.txt', 'ftp', ':', '//as.li.de', 'https', ':', '//doi.org/10.1109/5.771073', 'Emails', 'sdfsag', '@', 'gmail.com', 'asg.smg', '@', 'lu.se', 'Times', 'and', 'dates', '7d', '7', 'd', '00:30', 'min', '30min', '5h', '5', 'hours', '5', 'weeks', '5', 's', '5', 'sec', '5', 'seconds', '2019-09-01', '1', 'Sept', '2019', '1st', 'of', 'September', '2019', 'Sept', '1', ',', '2019', 'Sept', '1', '2019', '1.9.2019', '01.09.2019', 'Abbreviations', 'CytoC', 'hGal3', 'h-Gal13', 'Cyto-c', 'MERS', 'CD4+', 'CD4+', 'C.', 'elegans', 'growth', 'was', 'inhibited']\n",
      "\n",
      "[(',', 364737), ('.', 194063), ('of', 170681), (')', 168293), ('(', 168270), ('the', 109637), ('and', 105834), ('in', 86291), (':', 61359), ('1', 55011), ('to', 42551), ('a', 41430), ('cell', 37271), ('that', 31922), ('for', 31106), ('cells', 28675), ('by', 26651), ('2', 26011), ('university', 25937), ('apoptosis', 23071), ('is', 22768), ('death', 22613), ('doi', 22135), ('with', 20313), ('we', 18396), ('department', 17956), ('3', 16799), (';', 15636), ('cancer', 15333), ('as', 14592), (']', 14203), ('china', 13867), ('was', 12947), ('expression', 12936), ('[', 12800), ('pmid', 12668), ('information', 12358), ('author', 12229), ('4', 11818), ('medical', 10570)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens_abstract = word_tokenize(abstract)\n",
    "tokens_examples = word_tokenize(examples)\n",
    "tokens_cd_abstracts = word_tokenize(cd_abstracts)\n",
    "counts_cd_abstracts = FreqDist(tokens_cd_abstracts)\n",
    "\n",
    "print(len(tokens_abstract))\n",
    "print(len(tokens_examples))\n",
    "print(len(tokens_cd_abstracts))\n",
    "print()\n",
    "print(tokens_abstract[:40])\n",
    "print()\n",
    "print(tokens_examples)\n",
    "print()\n",
    "print(counts_cd_abstracts.most_common(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488\n",
      "394\n",
      "4467643\n",
      "\n",
      "['1.', 'cell', 'death', 'differ.', '2019', 'dec', '20.', 'doi', ':', '10.1038/s41418-019-0483-6.', '[', 'epub', 'ahead', 'of', 'print', ']', 'hnrnp', 'f/h', 'associate', 'with', 'hterc', 'and', 'telomerase', 'holoenzyme', 'to', 'modulate', 'telomerase', 'function', 'and', 'promote', 'cell', 'proliferation.', 'xu', 'c', '(', '1', ')', ',', 'xie', 'n']\n",
      "\n",
      "['Compound', 'words', 'Hydrogen', 'peroxide', 'causes', 'cell', 'death', 'Cell', 'death', 'is', 'caused', 'by', 'hydrogen', 'peroxide', 'UV', 'radiation', 'kills', 'cancer', 'cells', 'Hyphenated', 'compound', 'words', 'co-localization', 'Co-localization', 'wild-type', 'Wild-type', 'TLR-4', 'X-ray', 'Slashes', 'downregulation/mutation', 'Downregulation/mutation', 'Downregulation/Mutation', 'P53/73', 'p53/73', 'Omi/HtrA2', 'HER2/Neu', 'mg/ml', '&', 'Material', '&', 'Methods', 'material', '&', 'methods', '‘', \"'\", '``', 'Parkinson', '’', 's', 'can', '’', 't', 'wouldn', '’', 't', 'haven', '’', 't', 'hadn', '’', 't', 'shouldn', '’', 't', 'cells', '’', 'circumference', '‘', 'localization', '’', 'Parkinson', \"'s\", 'ca', \"n't\", 'would', \"n't\", 'have', \"n't\", 'had', \"n't\", 'should', \"n't\", 'cells', \"'\", \"'localization\", \"'\", \"''\", 'localization', \"''\", 'Non-alphanumerical', 'symbols', 'TNF-α', 'Brackets', '(', 'cells', ')', '[', 'cells', ']', '{', 'cells', '}', '<', 'cells', '>', '(', 'Cells', ')', '[', 'Cells', ']', '{', 'Cells', '}', '<', 'Cells', '>', '(', 'GAPDH', ')', '[', 'GAPDH', ']', '{', 'GAPDH', '}', '<', 'GAPDH', '>', '(', 'cells', ')', '(', 'cells', ')', 'A', ')', '2', ')', 'Combined', 'letters', 'and', 'punctuation', 'A.', 'e.g.', 'e.g.', ',', 'i.e.', 'p.o.', 'The', 'cell', 'is', 'dead.', 'Therefore', ',', 'we', 'Combined', 'letters', 'and', 'numbers', 'O2', '30th', 'LAMP2', 'log2', '2nd', 'Numbers', 'with', 'blanks', '4', '000', '453', 'Combined', 'numbers', 'and', 'punctuation', '3,000,000', '1/2', '76', '%', '1.4', '1-20', '1', ')', '1.', 'Mathematical', 'operators', '5*4', '5x4', '5⋅4', '56/8', '5+70=75', '5', '+', '70', '=', '75', '5-4', '-40', '6.65×10^−34', '6.65', '×', '10^−34', '20+/-5', '5.6-7.5', '%', '7^3', '5˃3', '5˃=x', 'Units', '20', 'mg/ml', '20', 'mg/mL', '20', 'µl/ml', '20', 'µg/mol', '20', 'm/s', '20', 'Gy', '20Gy', '20', '°C', '20°C', '20mmol', '20', 'mg/mg/h', 'Nucleotide', 'sequences', '5', '’', '-TTAC-3', '’', 'GGGCAAATT', 'GGGCAAAUU', 'Gene', ',', 'RNA', ',', 'Protein', 'names', 'miR-643', 'LAMP2', 'Gal1-3', 'leuAum', 'leuAcs', 'leuA+', 'leuA−', 'ΔleuA', 'leuA-lacZ', 'leuA', ':', 'lacZ', 'leuA', ':', ':Tn10', 'ΩleuA', 'ΔleuA', ':', ':nptII', '(', 'KanR', ')', 'mTOR', 'Chemicals', 'HC9H7O4', '2-acetyloxybenzoic', 'acid', 'InChI=1S/C9H8O4/c1-6', '(', '10', ')', '13-8-5-3-2-4-7', '(', '8', ')', '9', '(', '11', ')', '12/h2-5H,1H3', ',', '(', 'H,11,12', ')', 'BSYNRYMUTXBXSQ-UHFFFAOYSA-N', 'CC', '(', '=O', ')', 'OC1=CC=CC=C1C', '(', '=O', ')', 'O', 'Ca2+', 'Identifiers', '50-78-2', 'GAL3_HUMAN', 'P2446246', 'NM_235235', 'Complex', 'combinations', 'LAMP1/2', 'LAMP1-2', '(', 'LAMP1-2', ')', '(', 'see', 'below', '(', 'Fig.1', ')', ')', 'A-B', ')', 'Hypertext', '&', 'lt', '&', 'quot', 'Links', 'http', ':', '//www.lu.se', 'https', ':', '//ai-lu.com/gst.txt', 'ftp', ':', '//as.li.de', 'https', ':', '//doi.org/10.1109/5.771073', 'Emails', 'sdfsag', '@', 'gmail.com', 'asg.smg', '@', 'lu.se', 'Times', 'and', 'dates', '7d', '7', 'd', '00:30', 'min', '30min', '5h', '5', 'hours', '5', 'weeks', '5', 's', '5', 'sec', '5', 'seconds', '2019-09-01', '1', 'Sept', '2019', '1st', 'of', 'September', '2019', 'Sept', '1', ',', '2019', 'Sept', '1', '2019', '1.9.2019', '01.09.2019', 'Abbreviations', 'CytoC', 'hGal3', 'h-Gal13', 'Cyto-c', 'MERS', 'CD4+', 'CD4+', 'C.', 'elegans', 'growth', 'was', 'inhibited']\n",
      "\n",
      "[(',', 364737), ('of', 170681), (')', 168293), ('(', 168270), ('the', 109637), ('and', 105834), ('in', 86287), (':', 61359), ('1', 55010), ('to', 42550), ('a', 41426), ('cell', 37144), ('that', 31920), ('for', 31106), ('by', 26649), ('2', 26008), ('university', 25927), ('is', 22764), ('doi', 22135), ('cells', 21642), ('with', 20312), ('death', 20248), ('we', 18394), ('department', 17956), ('3', 16796), ('apoptosis', 16147), (';', 15636), ('as', 14586), (']', 14203), ('cancer', 14020), ('was', 12947), ('[', 12800), ('pmid', 12668), ('china.', 12433), ('information', 12343), ('author', 12227), ('expression', 11829), ('4', 11817), ('.', 11094), ('medical', 10570)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens_abstract = tokenizer.tokenize(abstract)\n",
    "tokens_examples = tokenizer.tokenize(examples)\n",
    "tokens_cd_abstracts = tokenizer.tokenize(cd_abstracts)\n",
    "counts_cd_abstracts = FreqDist(tokens_cd_abstracts)\n",
    "\n",
    "print(len(tokens_abstract))\n",
    "print(len(tokens_examples))\n",
    "print(len(tokens_cd_abstracts))\n",
    "print()\n",
    "print(tokens_abstract[:40])\n",
    "print()\n",
    "print(tokens_examples)\n",
    "print()\n",
    "print(counts_cd_abstracts.most_common(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scispacy tokenization (en_core_sci_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "path = 'C:\\\\Users\\\\Sonja\\\\Anaconda3\\\\envs\\\\scispacy\\\\Lib\\\\site-packages\\\\en_core_sci_md\\\\en_core_sci_md-0.2.4'\n",
    "#the model was downloaded from https://github.com/allenai/scispacy\n",
    "nlp = spacy.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.lang.en.English object at 0x0000029C088A08C8>\n",
      "25881725\n"
     ]
    }
   ],
   "source": [
    "print(nlp)\n",
    "print(len(cd_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the nlp.max_length limit. The limit is in number of characters. Then, when you call your spaCy pipeline, disable RAM-intensive parts such as ner and parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_abstracts_s = cd_abstracts[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example:\n",
    "#nlp.max_length = 26000000\n",
    "#doc_cd_ab = nlp(cd_abstracts, disable = ['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "585\n",
      "93512\n",
      "\n",
      "['1', '.', 'cell', 'death', 'differ', '.', '2019', 'dec', '20', '.', 'doi', ':', '10.1038/s41418', '-', '019', '-', '0483', '-', '6', '.', '[', 'epub', 'ahead', 'of', '\\n', 'print', ']', '\\n\\n', 'hnrnp', 'f/h', 'associate', 'with', 'hterc', 'and', 'telomerase', 'holoenzyme', 'to', 'modulate', 'telomerase', '\\n']\n",
      "\n",
      "['Compound', 'words', '\\n', 'Hydrogen', 'peroxide', 'causes', 'cell', 'death', '\\n', 'Cell', 'death', 'is', 'caused', 'by', 'hydrogen', 'peroxide', '\\n', 'UV', 'radiation', 'kills', 'cancer', 'cells', '\\n\\n', 'Hyphenated', 'compound', 'words', '\\n', 'co-localization', '\\n', 'Co-localization', '\\n', 'wild-type', '\\n', 'Wild-type', '\\n', 'TLR-4', '\\n', 'X-ray', '\\n\\n', 'Slashes', '\\n', 'downregulation/mutation', '\\n', 'Downregulation/mutation', '\\n', 'Downregulation/Mutation', '\\n', 'P53/73', '\\n', 'p53/73', '\\n', 'Omi/HtrA2', '\\n', 'HER2/Neu', '\\n', 'mg/ml', '\\n\\n', '&', '\\n', 'Material&Methods', '\\n', 'material&methods', '\\n\\n', '‘', \"'\", '\"', '\\n', 'Parkinson', '’s', '\\n', 'ca', 'n’t', '\\n', 'would', 'n’t', '\\n', 'have', 'n’t', '\\n', 'had', 'n’t', '\\n', 'should', 'n’t', '\\n', 'cells', '’', 'circumference', '\\n', '‘', 'localization', '’', '\\n', 'Parkinson', \"'s\", '\\n', 'ca', \"n't\", '\\n', 'would', \"n't\", '\\n', 'have', \"n't\", '\\n', 'had', \"n't\", '\\n', 'should', \"n't\", '\\n', 'cells', \"'\", '\\n', \"'\", 'localization', \"'\", '\\n', '\"', 'localization', '\"', '\\n\\n', 'Non-alphanumerical', 'symbols', '\\n', 'TNF-α', '\\n\\n', 'Brackets', '\\n', '(', 'cells', ')', '\\n', '[', 'cells', ']', '\\n', '{', 'cells', '}', '\\n', '<', 'cells', '>', '\\n', '(', 'Cells', ')', '\\n', '[', 'Cells', ']', '\\n', '{', 'Cells', '}', '\\n', '<', 'Cells', '>', '\\n', '(', 'GAPDH', ')', '\\n', '[', 'GAPDH', ']', '\\n', '{', 'GAPDH', '}', '\\n', '<', 'GAPDH', '>', '\\n', '(', 'cells', ')', '\\n', '(', 'cells', ')', '\\n', 'A', ')', '\\n', '2', ')', '\\n\\n', 'Combined', 'letters', 'and', 'punctuation', '\\n', 'A.', '\\n', 'e.g.', '\\n', 'e.g.', ',', '\\n', 'i.e.', '\\n', 'p.o', '.', '\\n', 'The', 'cell', 'is', 'dead', '.', 'Therefore', ',', 'we', '\\n\\n', 'Combined', 'letters', 'and', 'numbers', '\\n', 'O2', '\\n', '30th', '\\n', 'LAMP2', '\\n', 'log2', '\\n', '2nd', '\\n\\n', 'Numbers', 'with', 'blanks', '\\n', '4', '000', '453', '\\n\\n', 'Combined', 'numbers', 'and', 'punctuation', '\\n', '3,000,000', '\\n', '1/2', '\\n', '76', '%', '\\n', '1.4', '\\n', '1', '-', '20', '\\n', '1', ')', '\\n', '1', '.', '\\n\\n', 'Mathematical', 'operators', '\\n', '5', '*', '4', '\\n', '5x4', '\\n', '5⋅4', '\\n', '56/8', '\\n', '5', '+', '70=75', '\\n', '5', '+', '70', '=', '75', '\\n', '5', '-', '4', '\\n', '-40', '\\n', '6.65', '×', '10^−34', '\\n', '6.65', '×', '10^−34', '\\n', '20+/-5', '\\n', '5.6', '-', '7.5', '%', '\\n', '7', '^', '3', '\\n', '5˃3', '\\n', '5˃=x', '\\n\\n', 'Units', '\\n', '20', 'mg/ml', '\\n', '20', 'mg/mL', '\\n', '20', 'µl/ml', '\\n', '20', 'µg/mol', '\\n', '20', 'm/s', '\\n', '20', 'Gy', '\\n', '20Gy', '\\n', '20', '°', 'C', '\\n', '20', '°', 'C', '\\n', '20mmol', '\\n', '20', 'mg/mg/h', '\\n\\n', 'Nucleotide', 'sequences', '\\n', '5’-TTAC-3', '’', '\\n', 'GGGCAAATT', '\\n', 'GGGCAAAUU', '\\n\\n', 'Gene', ',', 'RNA', ',', 'Protein', 'names', '\\n', 'miR-643', '\\n', 'LAMP2', '\\n', 'Gal1', '-', '3', '\\n', 'leuAum', '\\n', 'leuAcs', '\\n', 'leuA+', '\\n', 'leuA−', '\\n', 'ΔleuA', '\\n', 'leuA-lacZ', '\\n', 'leuA', ':', 'lacZ', '\\n', 'leuA::Tn10', '\\n', 'ΩleuA', '\\n', 'ΔleuA::nptII(KanR', ')', '\\n', 'mTOR', '\\n\\n', 'Chemicals', '\\n', 'HC9H7O4', '\\n', '2-acetyloxybenzoic', 'acid', '\\n', 'InChI=1S/C9H8O4/c1', '-', '6(10)13', '-', '8', '-', '5', '-', '3', '-', '2', '-', '4', '-', '7(8)9(11)12/h2', '-', '5H,1H3,(H,11,12', ')', '\\n', 'BSYNRYMUTXBXSQ-UHFFFAOYSA-N', '\\n', 'CC(=O)OC1=CC', '=', 'CC', '=', 'C1C(=O)O', '\\n', 'Ca2', '+', '\\n\\n', 'Identifiers', '\\n', '50', '-', '78', '-', '2', '\\n', 'GAL3_HUMAN', '\\n', 'P2446246', '\\n', 'NM_235235', '\\n\\n', 'Complex', 'combinations', '\\n', 'LAMP1/2', '\\n', 'LAMP1', '-', '2', '\\n', '(', 'LAMP1', '-', '2', ')', '\\n', '(', 'see', 'below', '(', 'Fig.1', ')', ')', '\\n', 'A-B', ')', '\\n\\n\\n', 'Hypertext', '\\n', '&', 'lt', '\\n', '&', 'quot', '\\n\\n', 'Links', '\\n', 'http://www.lu.se', '\\n', 'https://ai-lu.com/gst.txt', '\\n', 'ftp://as.li.de', '\\n', 'https://doi.org/10.1109/5.771073', '\\n\\n', 'Emails', '\\n', 'sdfsag@gmail.com', '\\n', 'asg.smg@lu.se', '\\n\\n', 'Times', 'and', 'dates', '\\n', '7d', '\\n', '7', 'd', '\\n', '00:30', 'min', '\\n', '30min', '\\n', '5h', '\\n', '5', 'hours', '\\n', '5', 'weeks', '\\n', '5', 's', '\\n', '5', 'sec', '\\n', '5', 'seconds', '\\n', '2019', '-', '09', '-', '01', '\\n', '1', 'Sept', '2019', '\\n', '1st', 'of', 'September', '2019', '\\n', 'Sept', '1', ',', '2019', '\\n', 'Sept', '1', '2019', '\\n', '1.9.2019', '\\n', '01.09.2019', '\\n\\n', 'Abbreviations', '\\n', 'CytoC', '\\n', 'hGal3', '\\n', 'h-Gal13', '\\n', 'Cyto-c', '\\n', 'MERS', '\\n', 'CD4', '+', '\\n', 'CD4', '+', '\\n', 'C.', 'elegans', 'growth', 'was', 'inhibited', '\\n']\n",
      "\n",
      "[(',', 8993), ('\\n', 6586), ('.', 4613), ('of', 3688), (')', 2496), ('and', 2045), ('the', 1795), ('in', 1437), ('-', 1194), ('\\n\\n', 1008), (':', 964), ('university', 875), ('to', 715), ('(', 632), ('a', 591), ('china', 586), ('cell', 571), ('that', 500), ('for', 412), ('by', 405), ('cancer', 393), ('doi', 391), ('019', 391), ('is', 384), ('cells', 382), ('hospital', 377), ('medical', 331), ('medicine', 324), ('death', 304), ('with', 304), ('we', 303), ('10.1038/s41419', 274), ('as', 260), ('laboratory', 251), ('2019', 229), ('research', 227), ('expression', 217), ('was', 215), ('information', 198), ('author', 196)]\n"
     ]
    }
   ],
   "source": [
    "doc_ab = nlp(abstract)\n",
    "tokens_abstract = [token.text for token in doc_ab]\n",
    "\n",
    "doc_ex = nlp(examples)\n",
    "tokens_examples = [token.text for token in doc_ex]\n",
    "\n",
    "doc_cd_ab_s = nlp(cd_abstracts_s)\n",
    "tokens_cd_abstracts_s = [token.text for token in doc_cd_ab_s]\n",
    "\n",
    "counts_cd_abstracts_s = FreqDist(tokens_cd_abstracts_s)\n",
    "\n",
    "print(len(tokens_abstract))\n",
    "print(len(tokens_examples))\n",
    "print(len(tokens_cd_abstracts_s))\n",
    "print()\n",
    "print(tokens_abstract[:40])\n",
    "print()\n",
    "print(tokens_examples)\n",
    "print()\n",
    "print(counts_cd_abstracts_s.most_common(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spacy default tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547\n",
      "643\n",
      "98953\n",
      "\n",
      "['1', '.', 'cell', 'death', 'differ', '.', '2019', 'dec', '20', '.', 'doi', ':', '10.1038', '/', 's41418', '-', '019', '-', '0483', '-', '6', '.', '[', 'epub', 'ahead', 'of', '\\n', 'print', ']', '\\n\\n', 'hnrnp', 'f', '/', 'h', 'associate', 'with', 'hterc', 'and', 'telomerase', 'holoenzyme']\n",
      "\n",
      "['Compound', 'words', '\\n', 'Hydrogen', 'peroxide', 'causes', 'cell', 'death', '\\n', 'Cell', 'death', 'is', 'caused', 'by', 'hydrogen', 'peroxide', '\\n', 'UV', 'radiation', 'kills', 'cancer', 'cells', '\\n\\n', 'Hyphenated', 'compound', 'words', '\\n', 'co', '-', 'localization', '\\n', 'Co', '-', 'localization', '\\n', 'wild', '-', 'type', '\\n', 'Wild', '-', 'type', '\\n', 'TLR-4', '\\n', 'X', '-', 'ray', '\\n\\n', 'Slashes', '\\n', 'downregulation', '/', 'mutation', '\\n', 'Downregulation', '/', 'mutation', '\\n', 'Downregulation', '/', 'Mutation', '\\n', 'P53/73', '\\n', 'p53/73', '\\n', 'Omi', '/', 'HtrA2', '\\n', 'HER2', '/', 'Neu', '\\n', 'mg', '/', 'ml', '\\n\\n', '&', '\\n', 'Material&Methods', '\\n', 'material&methods', '\\n\\n', '‘', \"'\", '\"', '\\n', 'Parkinson', '’s', '\\n', 'ca', 'n’t', '\\n', 'would', 'n’t', '\\n', 'have', 'n’t', '\\n', 'had', 'n’t', '\\n', 'should', 'n’t', '\\n', 'cells', '’', 'circumference', '\\n', '‘', 'localization', '’', '\\n', 'Parkinson', \"'s\", '\\n', 'ca', \"n't\", '\\n', 'would', \"n't\", '\\n', 'have', \"n't\", '\\n', 'had', \"n't\", '\\n', 'should', \"n't\", '\\n', 'cells', \"'\", '\\n', \"'\", 'localization', \"'\", '\\n', '\"', 'localization', '\"', '\\n\\n', 'Non', '-', 'alphanumerical', 'symbols', '\\n', 'TNF', '-', 'α', '\\n\\n', 'Brackets', '\\n', '(', 'cells', ')', '\\n', '[', 'cells', ']', '\\n', '{', 'cells', '}', '\\n', '<', 'cells', '>', '\\n', '(', 'Cells', ')', '\\n', '[', 'Cells', ']', '\\n', '{', 'Cells', '}', '\\n', '<', 'Cells', '>', '\\n', '(', 'GAPDH', ')', '\\n', '[', 'GAPDH', ']', '\\n', '{', 'GAPDH', '}', '\\n', '<', 'GAPDH', '>', '\\n', '(', 'cells', ')', '\\n', '(', 'cells', ')', '\\n', 'A', ')', '\\n', '2', ')', '\\n\\n', 'Combined', 'letters', 'and', 'punctuation', '\\n', 'A.', '\\n', 'e.g.', '\\n', 'e.g.', ',', '\\n', 'i.e.', '\\n', 'p.o', '.', '\\n', 'The', 'cell', 'is', 'dead', '.', 'Therefore', ',', 'we', '\\n\\n', 'Combined', 'letters', 'and', 'numbers', '\\n', 'O2', '\\n', '30th', '\\n', 'LAMP2', '\\n', 'log2', '\\n', '2nd', '\\n\\n', 'Numbers', 'with', 'blanks', '\\n', '4', '000', '453', '\\n\\n', 'Combined', 'numbers', 'and', 'punctuation', '\\n', '3,000,000', '\\n', '1/2', '\\n', '76', '%', '\\n', '1.4', '\\n', '1', '-', '20', '\\n', '1', ')', '\\n', '1', '.', '\\n\\n', 'Mathematical', 'operators', '\\n', '5', '*', '4', '\\n', '5x4', '\\n', '5⋅4', '\\n', '56/8', '\\n', '5', '+', '70=75', '\\n', '5', '+', '70', '=', '75', '\\n', '5', '-', '4', '\\n', '-40', '\\n', '6.65×10^−34', '\\n', '6.65', '×', '10^−34', '\\n', '20+/-5', '\\n', '5.6', '-', '7.5', '%', '\\n', '7', '^', '3', '\\n', '5˃3', '\\n', '5˃=x', '\\n\\n', 'Units', '\\n', '20', 'mg', '/', 'ml', '\\n', '20', 'mg', '/', 'mL', '\\n', '20', 'µl', '/', 'ml', '\\n', '20', 'µg', '/', 'mol', '\\n', '20', 'm', '/', 's', '\\n', '20', 'Gy', '\\n', '20Gy', '\\n', '20', '°', 'C', '\\n', '20', '°', 'C', '\\n', '20mmol', '\\n', '20', 'mg', '/', 'mg', '/', 'h', '\\n\\n', 'Nucleotide', 'sequences', '\\n', '5’-TTAC-3', '’', '\\n', 'GGGCAAATT', '\\n', 'GGGCAAAUU', '\\n\\n', 'Gene', ',', 'RNA', ',', 'Protein', 'names', '\\n', 'miR-643', '\\n', 'LAMP2', '\\n', 'Gal1', '-', '3', '\\n', 'leuAum', '\\n', 'leuAcs', '\\n', 'leuA+', '\\n', 'leuA−', '\\n', 'ΔleuA', '\\n', 'leuA', '-', 'lacZ', '\\n', 'leuA', ':', 'lacZ', '\\n', 'leuA::Tn10', '\\n', 'ΩleuA', '\\n', 'ΔleuA::nptII(KanR', ')', '\\n', 'mTOR', '\\n\\n', 'Chemicals', '\\n', 'HC9H7O4', '\\n', '2-acetyloxybenzoic', 'acid', '\\n', 'InChI=1S', '/', 'C9H8O4', '/', 'c1', '-', '6(10)13', '-', '8', '-', '5', '-', '3', '-', '2', '-', '4', '-', '7(8)9(11)12', '/', 'h2', '-', '5H,1H3,(H,11,12', ')', '\\n', 'BSYNRYMUTXBXSQ', '-', 'UHFFFAOYSA', '-', 'N', '\\n', 'CC(=O)OC1', '=', 'CC', '=', 'CC', '=', 'C1C(=O)O', '\\n', 'Ca2', '+', '\\n\\n', 'Identifiers', '\\n', '50', '-', '78', '-', '2', '\\n', 'GAL3_HUMAN', '\\n', 'P2446246', '\\n', 'NM_235235', '\\n\\n', 'Complex', 'combinations', '\\n', 'LAMP1/2', '\\n', 'LAMP1', '-', '2', '\\n', '(', 'LAMP1', '-', '2', ')', '\\n', '(', 'see', 'below', '(', 'Fig.1', ')', ')', '\\n', 'A', '-', 'B', ')', '\\n\\n\\n', 'Hypertext', '\\n', '&', 'lt', '\\n', '&', 'quot', '\\n\\n', 'Links', '\\n', 'http://www.lu.se', '\\n', 'https://ai-lu.com/gst.txt', '\\n', 'ftp://as.li.de', '\\n', 'https://doi.org/10.1109/5.771073', '\\n\\n', 'Emails', '\\n', 'sdfsag@gmail.com', '\\n', 'asg.smg@lu.se', '\\n\\n', 'Times', 'and', 'dates', '\\n', '7d', '\\n', '7', 'd', '\\n', '00:30', 'min', '\\n', '30min', '\\n', '5h', '\\n', '5', 'hours', '\\n', '5', 'weeks', '\\n', '5', 's', '\\n', '5', 'sec', '\\n', '5', 'seconds', '\\n', '2019', '-', '09', '-', '01', '\\n', '1', 'Sept', '2019', '\\n', '1st', 'of', 'September', '2019', '\\n', 'Sept', '1', ',', '2019', '\\n', 'Sept', '1', '2019', '\\n', '1.9.2019', '\\n', '01.09.2019', '\\n\\n', 'Abbreviations', '\\n', 'CytoC', '\\n', 'hGal3', '\\n', 'h', '-', 'Gal13', '\\n', 'Cyto', '-', 'c', '\\n', 'MERS', '\\n', 'CD4', '+', '\\n', 'CD4', '+', '\\n', 'C.', 'elegans', 'growth', 'was', 'inhibited', '\\n']\n",
      "\n",
      "[(',', 8993), ('\\n', 6586), ('.', 4621), ('of', 3692), ('-', 2720), (')', 2499), ('and', 2045), ('(', 1845), ('the', 1796), ('in', 1438), ('\\n\\n', 1008), (':', 964), ('university', 883), ('to', 726), ('cell', 609), ('a', 605), ('china', 586), ('/', 580), ('that', 500), ('cancer', 426), ('for', 412), ('by', 409), ('doi', 391), ('019', 391), ('cells', 391), ('is', 388), ('hospital', 378), ('10.1038', 373), ('medical', 331), ('medicine', 326), ('death', 309), ('with', 304), ('we', 303), ('s41419', 274), ('as', 260), ('laboratory', 251), ('2019', 229), ('research', 227), ('expression', 223), ('was', 215)]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "tokens_abstract = tokenizer(abstract)\n",
    "token_list_ab = []\n",
    "for token in tokens_abstract:\n",
    "    token_list_ab.append(token.text)\n",
    "    \n",
    "tokens_examples = tokenizer(examples)\n",
    "token_list_ex = []\n",
    "for token in tokens_examples:\n",
    "    token_list_ex.append(token.text)\n",
    "\n",
    "tokens_cd_abstracts_s = tokenizer(cd_abstracts_s)\n",
    "token_list_cd_ab_s = []\n",
    "for token in tokens_cd_abstracts_s:\n",
    "    token_list_cd_ab_s.append(token.text)\n",
    "    \n",
    "    \n",
    "counts_cd_abstracts_s = FreqDist(token_list_cd_ab_s)\n",
    "\n",
    "\n",
    "print(len(token_list_ab))\n",
    "print(len(token_list_ex))\n",
    "print(len(token_list_cd_ab_s))\n",
    "print()\n",
    "print(token_list_ab[:40])\n",
    "print()\n",
    "print(token_list_ex)\n",
    "print()\n",
    "print(counts_cd_abstracts_s.most_common(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scispacy custom tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be identical to using the scispacy model as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scispacy\n",
    "from scispacy.custom_tokenizer import combined_rule_tokenizer\n",
    "tokenizer = combined_rule_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "585\n",
      "93512\n",
      "\n",
      "['1', '.', 'cell', 'death', 'differ', '.', '2019', 'dec', '20', '.', 'doi', ':', '10.1038/s41418', '-', '019', '-', '0483', '-', '6', '.', '[', 'epub', 'ahead', 'of', '\\n', 'print', ']', '\\n\\n', 'hnrnp', 'f/h', 'associate', 'with', 'hterc', 'and', 'telomerase', 'holoenzyme', 'to', 'modulate', 'telomerase', '\\n']\n",
      "\n",
      "['Compound', 'words', '\\n', 'Hydrogen', 'peroxide', 'causes', 'cell', 'death', '\\n', 'Cell', 'death', 'is', 'caused', 'by', 'hydrogen', 'peroxide', '\\n', 'UV', 'radiation', 'kills', 'cancer', 'cells', '\\n\\n', 'Hyphenated', 'compound', 'words', '\\n', 'co-localization', '\\n', 'Co-localization', '\\n', 'wild-type', '\\n', 'Wild-type', '\\n', 'TLR-4', '\\n', 'X-ray', '\\n\\n', 'Slashes', '\\n', 'downregulation/mutation', '\\n', 'Downregulation/mutation', '\\n', 'Downregulation/Mutation', '\\n', 'P53/73', '\\n', 'p53/73', '\\n', 'Omi/HtrA2', '\\n', 'HER2/Neu', '\\n', 'mg/ml', '\\n\\n', '&', '\\n', 'Material&Methods', '\\n', 'material&methods', '\\n\\n', '‘', \"'\", '\"', '\\n', 'Parkinson', '’s', '\\n', 'ca', 'n’t', '\\n', 'would', 'n’t', '\\n', 'have', 'n’t', '\\n', 'had', 'n’t', '\\n', 'should', 'n’t', '\\n', 'cells', '’', 'circumference', '\\n', '‘', 'localization', '’', '\\n', 'Parkinson', \"'s\", '\\n', 'ca', \"n't\", '\\n', 'would', \"n't\", '\\n', 'have', \"n't\", '\\n', 'had', \"n't\", '\\n', 'should', \"n't\", '\\n', 'cells', \"'\", '\\n', \"'\", 'localization', \"'\", '\\n', '\"', 'localization', '\"', '\\n\\n', 'Non-alphanumerical', 'symbols', '\\n', 'TNF-α', '\\n\\n', 'Brackets', '\\n', '(', 'cells', ')', '\\n', '[', 'cells', ']', '\\n', '{', 'cells', '}', '\\n', '<', 'cells', '>', '\\n', '(', 'Cells', ')', '\\n', '[', 'Cells', ']', '\\n', '{', 'Cells', '}', '\\n', '<', 'Cells', '>', '\\n', '(', 'GAPDH', ')', '\\n', '[', 'GAPDH', ']', '\\n', '{', 'GAPDH', '}', '\\n', '<', 'GAPDH', '>', '\\n', '(', 'cells', ')', '\\n', '(', 'cells', ')', '\\n', 'A', ')', '\\n', '2', ')', '\\n\\n', 'Combined', 'letters', 'and', 'punctuation', '\\n', 'A.', '\\n', 'e.g.', '\\n', 'e.g.', ',', '\\n', 'i.e.', '\\n', 'p.o', '.', '\\n', 'The', 'cell', 'is', 'dead', '.', 'Therefore', ',', 'we', '\\n\\n', 'Combined', 'letters', 'and', 'numbers', '\\n', 'O2', '\\n', '30th', '\\n', 'LAMP2', '\\n', 'log2', '\\n', '2nd', '\\n\\n', 'Numbers', 'with', 'blanks', '\\n', '4', '000', '453', '\\n\\n', 'Combined', 'numbers', 'and', 'punctuation', '\\n', '3,000,000', '\\n', '1/2', '\\n', '76', '%', '\\n', '1.4', '\\n', '1', '-', '20', '\\n', '1', ')', '\\n', '1', '.', '\\n\\n', 'Mathematical', 'operators', '\\n', '5', '*', '4', '\\n', '5x4', '\\n', '5⋅4', '\\n', '56/8', '\\n', '5', '+', '70=75', '\\n', '5', '+', '70', '=', '75', '\\n', '5', '-', '4', '\\n', '-40', '\\n', '6.65', '×', '10^−34', '\\n', '6.65', '×', '10^−34', '\\n', '20+/-5', '\\n', '5.6', '-', '7.5', '%', '\\n', '7', '^', '3', '\\n', '5˃3', '\\n', '5˃=x', '\\n\\n', 'Units', '\\n', '20', 'mg/ml', '\\n', '20', 'mg/mL', '\\n', '20', 'µl/ml', '\\n', '20', 'µg/mol', '\\n', '20', 'm/s', '\\n', '20', 'Gy', '\\n', '20Gy', '\\n', '20', '°', 'C', '\\n', '20', '°', 'C', '\\n', '20mmol', '\\n', '20', 'mg/mg/h', '\\n\\n', 'Nucleotide', 'sequences', '\\n', '5’-TTAC-3', '’', '\\n', 'GGGCAAATT', '\\n', 'GGGCAAAUU', '\\n\\n', 'Gene', ',', 'RNA', ',', 'Protein', 'names', '\\n', 'miR-643', '\\n', 'LAMP2', '\\n', 'Gal1', '-', '3', '\\n', 'leuAum', '\\n', 'leuAcs', '\\n', 'leuA+', '\\n', 'leuA−', '\\n', 'ΔleuA', '\\n', 'leuA-lacZ', '\\n', 'leuA', ':', 'lacZ', '\\n', 'leuA::Tn10', '\\n', 'ΩleuA', '\\n', 'ΔleuA::nptII(KanR', ')', '\\n', 'mTOR', '\\n\\n', 'Chemicals', '\\n', 'HC9H7O4', '\\n', '2-acetyloxybenzoic', 'acid', '\\n', 'InChI=1S/C9H8O4/c1', '-', '6(10)13', '-', '8', '-', '5', '-', '3', '-', '2', '-', '4', '-', '7(8)9(11)12/h2', '-', '5H,1H3,(H,11,12', ')', '\\n', 'BSYNRYMUTXBXSQ-UHFFFAOYSA-N', '\\n', 'CC(=O)OC1=CC', '=', 'CC', '=', 'C1C(=O)O', '\\n', 'Ca2', '+', '\\n\\n', 'Identifiers', '\\n', '50', '-', '78', '-', '2', '\\n', 'GAL3_HUMAN', '\\n', 'P2446246', '\\n', 'NM_235235', '\\n\\n', 'Complex', 'combinations', '\\n', 'LAMP1/2', '\\n', 'LAMP1', '-', '2', '\\n', '(', 'LAMP1', '-', '2', ')', '\\n', '(', 'see', 'below', '(', 'Fig.1', ')', ')', '\\n', 'A-B', ')', '\\n\\n\\n', 'Hypertext', '\\n', '&', 'lt', '\\n', '&', 'quot', '\\n\\n', 'Links', '\\n', 'http://www.lu.se', '\\n', 'https://ai-lu.com/gst.txt', '\\n', 'ftp://as.li.de', '\\n', 'https://doi.org/10.1109/5.771073', '\\n\\n', 'Emails', '\\n', 'sdfsag@gmail.com', '\\n', 'asg.smg@lu.se', '\\n\\n', 'Times', 'and', 'dates', '\\n', '7d', '\\n', '7', 'd', '\\n', '00:30', 'min', '\\n', '30min', '\\n', '5h', '\\n', '5', 'hours', '\\n', '5', 'weeks', '\\n', '5', 's', '\\n', '5', 'sec', '\\n', '5', 'seconds', '\\n', '2019', '-', '09', '-', '01', '\\n', '1', 'Sept', '2019', '\\n', '1st', 'of', 'September', '2019', '\\n', 'Sept', '1', ',', '2019', '\\n', 'Sept', '1', '2019', '\\n', '1.9.2019', '\\n', '01.09.2019', '\\n\\n', 'Abbreviations', '\\n', 'CytoC', '\\n', 'hGal3', '\\n', 'h-Gal13', '\\n', 'Cyto-c', '\\n', 'MERS', '\\n', 'CD4', '+', '\\n', 'CD4', '+', '\\n', 'C.', 'elegans', 'growth', 'was', 'inhibited', '\\n']\n",
      "\n",
      "[(',', 8993), ('\\n', 6586), ('.', 4613), ('of', 3688), (')', 2496), ('and', 2045), ('the', 1795), ('in', 1437), ('-', 1194), ('\\n\\n', 1008), (':', 964), ('university', 875), ('to', 715), ('(', 632), ('a', 591), ('china', 586), ('cell', 571), ('that', 500), ('for', 412), ('by', 405), ('cancer', 393), ('doi', 391), ('019', 391), ('is', 384), ('cells', 382), ('hospital', 377), ('medical', 331), ('medicine', 324), ('death', 304), ('with', 304), ('we', 303), ('10.1038/s41419', 274), ('as', 260), ('laboratory', 251), ('2019', 229), ('research', 227), ('expression', 217), ('was', 215), ('information', 198), ('author', 196)]\n"
     ]
    }
   ],
   "source": [
    "tokens_abstract = tokenizer(abstract)\n",
    "token_list_ab = []\n",
    "for token in tokens_abstract:\n",
    "    token_list_ab.append(token.text)\n",
    "    \n",
    "tokens_examples = tokenizer(examples)\n",
    "token_list_ex = []\n",
    "for token in tokens_examples:\n",
    "    token_list_ex.append(token.text)\n",
    "\n",
    "tokens_cd_abstracts_s = tokenizer(cd_abstracts_s)\n",
    "token_list_cd_ab_s = []\n",
    "for token in tokens_cd_abstracts_s:\n",
    "    token_list_cd_ab_s.append(token.text)\n",
    "    \n",
    "    \n",
    "counts_cd_abstracts_s = FreqDist(token_list_cd_ab_s)\n",
    "\n",
    "\n",
    "print(len(token_list_ab))\n",
    "print(len(token_list_ex))\n",
    "print(len(token_list_cd_ab_s))\n",
    "print()\n",
    "print(token_list_ab[:40])\n",
    "print()\n",
    "print(token_list_ex)\n",
    "print()\n",
    "print(counts_cd_abstracts_s.most_common(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# syntok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508\n",
      "426\n",
      "95387\n",
      "\n",
      "['1', '.', 'cell', 'death', 'differ', '.', '2019', 'dec', '20', '.', 'doi', ':', '10.1038/s41418-019-0483-6', '.', '[', 'epub', 'ahead', 'of', 'print', ']', 'hnrnp', 'f/h', 'associate', 'with', 'hterc', 'and', 'telomerase', 'holoenzyme', 'to', 'modulate', 'telomerase', 'function', 'and', 'promote', 'cell', 'proliferation', '.', 'xu', 'c', '(']\n",
      "\n",
      "['Compound', 'words', 'Hydrogen', 'peroxide', 'causes', 'cell', 'death', 'Cell', 'death', 'is', 'caused', 'by', 'hydrogen', 'peroxide', 'UV', 'radiation', 'kills', 'cancer', 'cells', 'Hyphenated', 'compound', 'words', 'co', 'localization', 'Co', 'localization', 'wild', 'type', 'Wild', 'type', 'TLR', '4', 'X', 'ray', 'Slashes', 'downregulation/mutation', 'Downregulation/mutation', 'Downregulation/Mutation', 'P53/73', 'p53/73', 'Omi/Htr', 'A2', 'HER2/Neu', 'mg/ml', '&', 'Material&Methods', 'material&methods', '‘', \"'\", '\"', 'Parkinson', '’s', 'ca', 'not', 'would', 'not', 'have', 'not', 'had', 'not', 'should', 'not', 'cells', '’', 'circumference', '‘', 'localization', '’', 'Parkinson', \"'s\", 'ca', 'not', 'would', 'not', 'have', 'not', 'had', 'not', 'should', 'not', 'cells', \"'\", \"'\", 'localization', \"'\", '\"', 'localization', '\"', 'Non', 'alphanumerical', 'symbols', 'TNF', 'α', 'Brackets', '(', 'cells', ')', '[', 'cells', ']', '{', 'cells', '}', '<', 'cells', '>', '(', 'Cells', ')', '[', 'Cells', ']', '{', 'Cells', '}', '<', 'Cells', '>', '(', 'GAPDH', ')', '[', 'GAPDH', ']', '{', 'GAPDH', '}', '<', 'GAPDH', '>', '(', 'cells', ')', '(', 'cells', ')', 'A', ')', '2', ')', 'Combined', 'letters', 'and', 'punctuation', 'A', '.', 'e.g', '.', 'e.g', '.', ',', 'i.e', '.', 'p.o', '.', 'The', 'cell', 'is', 'dead', '.', 'Therefore', ',', 'we', 'Combined', 'letters', 'and', 'numbers', 'O2', '30th', 'LAMP2', 'log2', '2nd', 'Numbers', 'with', 'blanks', '4', '000', '453', 'Combined', 'numbers', 'and', 'punctuation', '3,000,000', '1/2', '76', '%', '1.4', '1-20', '1', ')', '1', '.', 'Mathematical', 'operators', '5*4', '5x4', '5⋅4', '56/8', '5+70=75', '5', '+', '70', '=', '75', '5-4', '-', '40', '6.65×10^−34', '6.65', '×', '10^−34', '20+/-5', '5.6-7.5', '%', '7^3', '5˃3', '5˃=x', 'Units', '20', 'mg/ml', '20', 'mg/m', 'L', '20', 'µl/ml', '20', 'µg/mol', '20', 'm/s', '20', 'Gy', '20Gy', '20', '°', 'C', '20°C', '20mmol', '20', 'mg/mg/h', 'Nucleotide', 'sequences', '5’-TTAC', '3', '’', 'GGGCAAATT', 'GGGCAAAUU', 'Gene', ',', 'RNA', ',', 'Protein', 'names', 'mi', 'R', '643', 'LAMP2', 'Gal1-3', 'leu', 'Aum', 'leu', 'Acs', 'leu', 'A', '+', 'leu', 'A', '−', 'Δleu', 'A', 'leu', 'A', 'lac', 'Z', 'leu', 'A:lac', 'Z', 'leu', 'A::Tn10', 'Ωleu', 'A', 'Δleu', 'A::npt', 'II', '(', 'Kan', 'R', ')', 'm', 'TOR', 'Chemicals', 'HC9H7O4', '2', 'acetyloxybenzoic', 'acid', 'In', 'Ch', 'I=1S/C9H8O4/c1-6', '(', '10', ')', '13-8-5-3-2-4-7', '(', '8', ')', '9', '(', '11', ')', '12/h2-5H', ',', '1H3,', '(', 'H', ',', '11,12', ')', 'BSYNRYMUTXBXSQ', 'UHFFFAOYSA', 'N', 'CC', '(', '=O', ')', 'OC1=CC=CC=C1C', '(', '=O', ')', 'O', 'Ca2', '+', 'Identifiers', '50-78-2', 'GAL3', 'HUMAN', 'P2446246', 'NM', '235235', 'Complex', 'combinations', 'LAMP1/2', 'LAMP1-2', '(', 'LAMP1-2', ')', '(', 'see', 'below', '(', 'Fig.1', ')', ')', 'A', 'B', ')', 'Hypertext', '&', 'lt', '&', 'quot', 'Links', 'http://www.lu.se', 'https://ai', 'lu.com/gst.txt', 'ftp://as.li.de', 'https://doi.org/10.1109/5.771073', 'Emails', 'sdfsag@gmail.com', 'asg.smg@lu.se', 'Times', 'and', 'dates', '7d', '7', 'd', '00:30', 'min', '30min', '5h', '5', 'hours', '5', 'weeks', '5', 's', '5', 'sec', '5', 'seconds', '2019-09-01', '1', 'Sept', '2019', '1st', 'of', 'September', '2019', 'Sept', '1', ',', '2019', 'Sept', '1', '2019', '1.9.2019', '01.09.2019', 'Abbreviations', 'Cyto', 'C', 'h', 'Gal3', 'h', 'Gal13', 'Cyto', 'c', 'MERS', 'CD4', '+', 'CD4', '+', 'C', '.', 'elegans', 'growth', 'was', 'inhibited', '']\n",
      "\n",
      "[(',', 8991), ('.', 4685), ('(', 4387), (')', 4387), ('of', 3692), ('and', 2045), ('the', 1823), ('in', 1439), ('1', 1286), (':', 963), ('university', 894), ('to', 726), ('a', 686), ('2', 675), ('cell', 611), ('china', 586), ('department', 562), ('that', 500), ('3', 494), ('cancer', 427), ('for', 412), ('by', 410), ('doi', 391), ('cells', 391), ('is', 389), ('4', 385), ('hospital', 378), ('medical', 341), ('medicine', 326), ('5', 318), ('death', 308), ('with', 304), ('we', 304), ('laboratory', 268), ('as', 260), ('institute', 253), ('6', 240), ('research', 238), ('key', 231), ('2019', 229)]\n"
     ]
    }
   ],
   "source": [
    "from syntok.tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer()  # optional: keep \"n't\" contractions and \"-\", \"_\" inside words as tokens\n",
    "\n",
    "token_list_ab = []\n",
    "for token in tokenizer.tokenize(abstract):\n",
    "    token_list_ab.append(token.value)\n",
    "\n",
    "token_list_ex = []\n",
    "for token in tokenizer.tokenize(examples):\n",
    "    token_list_ex.append(token.value)\n",
    "\n",
    "token_list_cd_ab_s = []\n",
    "for token in tokenizer.tokenize(cd_abstracts_s):\n",
    "    token_list_cd_ab_s.append(token.value)\n",
    "    \n",
    "    \n",
    "counts_cd_abstracts_s = FreqDist(token_list_cd_ab_s)\n",
    "\n",
    "\n",
    "print(len(token_list_ab))\n",
    "print(len(token_list_ex))\n",
    "print(len(token_list_cd_ab_s))\n",
    "print()\n",
    "print(token_list_ab[:40])\n",
    "print()\n",
    "print(token_list_ex)\n",
    "print()\n",
    "print(counts_cd_abstracts_s.most_common(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Token '' : '1' @ 0>\n",
      "<Token '' : '.' @ 1>\n",
      "<Token ' ' : 'cell' @ 3>\n",
      "<Token ' ' : 'death' @ 8>\n",
      "<Token ' ' : 'differ' @ 14>\n",
      "<Token '' : '.' @ 20>\n",
      "<Token ' ' : '2019' @ 22>\n",
      "<Token ' ' : 'dec' @ 27>\n",
      "<Token ' ' : '20' @ 31>\n",
      "<Token '' : '.' @ 33>\n",
      "<Token ' ' : 'doi' @ 35>\n",
      "<Token '' : ':' @ 38>\n",
      "<Token ' ' : '10.1038/s41418-019-0483-6' @ 40>\n",
      "<Token '' : '.' @ 65>\n",
      "<Token ' ' : '[' @ 67>\n",
      "<Token '' : 'epub' @ 68>\n",
      "<Token ' ' : 'ahead' @ 73>\n",
      "<Token ' ' : 'of' @ 79>\n",
      "<Token '\\n' : 'print' @ 82>\n",
      "<Token '' : ']' @ 87>\n",
      "<Token '\\n\\n' : 'hnrnp' @ 90>\n",
      "<Token ' ' : 'f/h' @ 96>\n",
      "<Token ' ' : 'associate' @ 100>\n",
      "<Token ' ' : 'with' @ 110>\n",
      "<Token ' ' : 'hterc' @ 115>\n",
      "<Token ' ' : 'and' @ 121>\n",
      "<Token ' ' : 'telomerase' @ 125>\n",
      "<Token ' ' : 'holoenzyme' @ 136>\n",
      "<Token ' ' : 'to' @ 147>\n",
      "<Token ' ' : 'modulate' @ 150>\n",
      "<Token ' ' : 'telomerase' @ 159>\n",
      "<Token '\\n' : 'function' @ 170>\n",
      "<Token ' ' : 'and' @ 179>\n",
      "<Token ' ' : 'promote' @ 183>\n",
      "<Token ' ' : 'cell' @ 191>\n",
      "<Token ' ' : 'proliferation' @ 196>\n",
      "<Token '' : '.' @ 209>\n",
      "<Token '\\n\\n' : 'xu' @ 212>\n",
      "<Token ' ' : 'c' @ 215>\n",
      "<Token '' : '(' @ 216>\n",
      "<Token '' : '1' @ 217>\n",
      "<Token '' : ')' @ 218>\n",
      "<Token '' : ',' @ 219>\n",
      "<Token ' ' : 'xie' @ 221>\n",
      "<Token ' ' : 'n' @ 225>\n",
      "<Token '' : '(' @ 226>\n",
      "<Token '' : '2' @ 227>\n",
      "<Token '' : ')' @ 228>\n",
      "<Token '' : ',' @ 229>\n",
      "<Token ' ' : 'su' @ 231>\n",
      "<Token ' ' : 'y' @ 234>\n",
      "<Token '' : '(' @ 235>\n",
      "<Token '' : '1' @ 236>\n",
      "<Token '' : ')' @ 237>\n",
      "<Token '' : ',' @ 238>\n",
      "<Token ' ' : 'sun' @ 240>\n",
      "<Token ' ' : 'z' @ 244>\n",
      "<Token '' : '(' @ 245>\n",
      "<Token '' : '1' @ 246>\n",
      "<Token '' : ')' @ 247>\n",
      "<Token '' : ',' @ 248>\n",
      "<Token ' ' : 'liang' @ 250>\n",
      "<Token ' ' : 'y' @ 256>\n",
      "<Token '' : '(' @ 257>\n",
      "<Token '' : '1' @ 258>\n",
      "<Token '' : ')' @ 259>\n",
      "<Token '' : ',' @ 260>\n",
      "<Token ' ' : 'zhang' @ 262>\n",
      "<Token ' ' : 'n' @ 268>\n",
      "<Token '' : '(' @ 269>\n",
      "<Token '' : '1' @ 270>\n",
      "<Token '' : ')' @ 271>\n",
      "<Token '' : ',' @ 272>\n",
      "<Token ' ' : 'liu' @ 274>\n",
      "<Token ' ' : 'd' @ 278>\n",
      "<Token '' : '(' @ 279>\n",
      "<Token '' : '1' @ 280>\n",
      "<Token '' : ')' @ 281>\n",
      "<Token '' : ',' @ 282>\n",
      "<Token ' ' : 'jia' @ 284>\n",
      "<Token ' ' : 's' @ 288>\n",
      "<Token '' : '(' @ 289>\n",
      "<Token '' : '3' @ 290>\n",
      "<Token '' : ')' @ 291>\n",
      "<Token '' : ',' @ 292>\n",
      "<Token '\\n' : 'xing' @ 294>\n",
      "<Token ' ' : 'x' @ 299>\n",
      "<Token '' : '(' @ 300>\n",
      "<Token '' : '3' @ 301>\n",
      "<Token '' : ')' @ 302>\n",
      "<Token '' : ',' @ 303>\n",
      "<Token ' ' : 'han' @ 305>\n",
      "<Token ' ' : 'l' @ 309>\n",
      "<Token '' : '(' @ 310>\n",
      "<Token '' : '1' @ 311>\n",
      "<Token '' : ')' @ 312>\n",
      "<Token '' : ',' @ 313>\n",
      "<Token ' ' : 'li' @ 315>\n",
      "<Token ' ' : 'g' @ 318>\n",
      "<Token '' : '(' @ 319>\n",
      "<Token '' : '1' @ 320>\n",
      "<Token '' : ')' @ 321>\n",
      "<Token '' : ',' @ 322>\n",
      "<Token ' ' : 'tong' @ 324>\n",
      "<Token ' ' : 't' @ 329>\n",
      "<Token '' : '(' @ 330>\n",
      "<Token '' : '1' @ 331>\n",
      "<Token '' : ')' @ 332>\n",
      "<Token '' : ',' @ 333>\n",
      "<Token ' ' : 'chen' @ 335>\n",
      "<Token ' ' : 'j' @ 340>\n",
      "<Token '' : '(' @ 341>\n",
      "<Token '' : '4' @ 342>\n",
      "<Token '' : ')' @ 343>\n",
      "<Token '' : '.' @ 344>\n",
      "<Token '\\n\\n' : 'author' @ 347>\n",
      "<Token ' ' : 'information' @ 354>\n",
      "<Token '' : ':' @ 365>\n",
      "<Token ' \\n' : '(' @ 368>\n",
      "<Token '' : '1' @ 369>\n",
      "<Token '' : ')' @ 370>\n",
      "<Token '' : 'peking' @ 371>\n",
      "<Token ' ' : 'university' @ 378>\n",
      "<Token ' ' : 'research' @ 389>\n",
      "<Token ' ' : 'center' @ 398>\n",
      "<Token ' ' : 'on' @ 405>\n",
      "<Token ' ' : 'aging' @ 408>\n",
      "<Token '' : ',' @ 413>\n",
      "<Token ' ' : 'beijing' @ 415>\n",
      "<Token ' ' : 'key' @ 423>\n",
      "<Token ' ' : 'laboratory' @ 427>\n",
      "<Token ' ' : 'of' @ 438>\n",
      "<Token ' ' : 'protein' @ 441>\n",
      "<Token ' \\n' : 'posttranslational' @ 450>\n",
      "<Token ' ' : 'modifications' @ 468>\n",
      "<Token ' ' : 'and' @ 482>\n",
      "<Token ' ' : 'cell' @ 486>\n",
      "<Token ' ' : 'function' @ 491>\n",
      "<Token '' : ',' @ 499>\n",
      "<Token ' ' : 'department' @ 501>\n",
      "<Token ' ' : 'of' @ 512>\n",
      "<Token ' ' : 'biochemistry' @ 515>\n",
      "<Token ' ' : 'and' @ 528>\n",
      "<Token '\\n' : 'molecular' @ 532>\n",
      "<Token ' ' : 'biology' @ 542>\n",
      "<Token '' : ',' @ 549>\n",
      "<Token ' ' : 'department' @ 551>\n",
      "<Token ' ' : 'of' @ 562>\n",
      "<Token ' ' : 'integration' @ 565>\n",
      "<Token ' ' : 'of' @ 577>\n",
      "<Token ' ' : 'chinese' @ 580>\n",
      "<Token ' ' : 'and' @ 588>\n",
      "<Token ' ' : 'western' @ 592>\n",
      "<Token ' ' : 'medicine' @ 600>\n",
      "<Token '' : ',' @ 608>\n",
      "<Token '\\n' : 'school' @ 610>\n",
      "<Token ' ' : 'of' @ 617>\n",
      "<Token ' ' : 'basic' @ 620>\n",
      "<Token ' ' : 'medical' @ 626>\n",
      "<Token ' ' : 'science' @ 634>\n",
      "<Token '' : ',' @ 641>\n",
      "<Token ' ' : 'peking' @ 643>\n",
      "<Token ' ' : 'university' @ 650>\n",
      "<Token '' : ',' @ 660>\n",
      "<Token ' ' : 'beijing' @ 662>\n",
      "<Token '' : ',' @ 669>\n",
      "<Token ' ' : '100191' @ 671>\n",
      "<Token '' : ',' @ 677>\n",
      "<Token ' ' : 'china' @ 679>\n",
      "<Token '' : '.' @ 684>\n",
      "<Token '\\n' : '(' @ 686>\n",
      "<Token '' : '2' @ 687>\n",
      "<Token '' : ')' @ 688>\n",
      "<Token '' : 'department' @ 689>\n",
      "<Token ' ' : 'of' @ 700>\n",
      "<Token ' ' : 'physiology' @ 703>\n",
      "<Token ' ' : 'and' @ 714>\n",
      "<Token ' ' : 'pathophysiology' @ 718>\n",
      "<Token '' : ',' @ 733>\n",
      "<Token ' ' : 'school' @ 735>\n",
      "<Token ' ' : 'of' @ 742>\n",
      "<Token ' ' : 'basic' @ 745>\n",
      "<Token ' ' : 'medical' @ 751>\n",
      "<Token ' ' : 'science' @ 759>\n",
      "<Token '' : ',' @ 766>\n",
      "<Token '\\n' : 'peking' @ 768>\n",
      "<Token ' ' : 'university' @ 775>\n",
      "<Token '' : ',' @ 785>\n",
      "<Token ' ' : 'beijing' @ 787>\n",
      "<Token '' : ',' @ 794>\n",
      "<Token ' ' : '100191' @ 796>\n",
      "<Token '' : ',' @ 802>\n",
      "<Token ' ' : 'china' @ 804>\n",
      "<Token '' : '.' @ 809>\n",
      "<Token '\\n' : '(' @ 811>\n",
      "<Token '' : '3' @ 812>\n",
      "<Token '' : ')' @ 813>\n",
      "<Token '' : 'department' @ 814>\n",
      "<Token ' ' : 'of' @ 825>\n",
      "<Token ' ' : 'molecular' @ 828>\n",
      "<Token ' ' : 'diagnostics' @ 838>\n",
      "<Token '' : ',' @ 849>\n",
      "<Token ' ' : 'key' @ 851>\n",
      "<Token ' ' : 'laboratory' @ 855>\n",
      "<Token ' ' : 'of' @ 866>\n",
      "<Token ' ' : 'carcinogenesis' @ 869>\n",
      "<Token ' ' : 'and' @ 884>\n",
      "<Token '\\n' : 'translational' @ 888>\n",
      "<Token ' ' : 'research' @ 902>\n",
      "<Token ' ' : '(' @ 911>\n",
      "<Token '' : 'ministry' @ 912>\n",
      "<Token ' ' : 'of' @ 921>\n",
      "<Token ' ' : 'education' @ 924>\n",
      "<Token '' : ')' @ 933>\n",
      "<Token '' : ',' @ 934>\n",
      "<Token ' ' : 'peking' @ 936>\n",
      "<Token ' ' : 'university' @ 943>\n",
      "<Token ' ' : 'cancer' @ 954>\n",
      "<Token ' ' : 'hospital' @ 961>\n",
      "<Token '\\n' : '&' @ 970>\n",
      "<Token ' ' : 'institute' @ 972>\n",
      "<Token '' : ',' @ 981>\n",
      "<Token ' ' : 'beijing' @ 983>\n",
      "<Token '' : ',' @ 990>\n",
      "<Token ' ' : '100142' @ 992>\n",
      "<Token '' : ',' @ 998>\n",
      "<Token ' ' : 'china' @ 1000>\n",
      "<Token '' : '.' @ 1005>\n",
      "<Token '\\n' : '(' @ 1007>\n",
      "<Token '' : '4' @ 1008>\n",
      "<Token '' : ')' @ 1009>\n",
      "<Token '' : 'peking' @ 1010>\n",
      "<Token ' ' : 'university' @ 1017>\n",
      "<Token ' ' : 'research' @ 1028>\n",
      "<Token ' ' : 'center' @ 1037>\n",
      "<Token ' ' : 'on' @ 1044>\n",
      "<Token ' ' : 'aging' @ 1047>\n",
      "<Token '' : ',' @ 1052>\n",
      "<Token ' ' : 'beijing' @ 1054>\n",
      "<Token ' ' : 'key' @ 1062>\n",
      "<Token ' ' : 'laboratory' @ 1066>\n",
      "<Token ' ' : 'of' @ 1077>\n",
      "<Token ' ' : 'protein' @ 1080>\n",
      "<Token ' \\n' : 'posttranslational' @ 1089>\n",
      "<Token ' ' : 'modifications' @ 1107>\n",
      "<Token ' ' : 'and' @ 1121>\n",
      "<Token ' ' : 'cell' @ 1125>\n",
      "<Token ' ' : 'function' @ 1130>\n",
      "<Token '' : ',' @ 1138>\n",
      "<Token ' ' : 'department' @ 1140>\n",
      "<Token ' ' : 'of' @ 1151>\n",
      "<Token ' ' : 'biochemistry' @ 1154>\n",
      "<Token ' ' : 'and' @ 1167>\n",
      "<Token '\\n' : 'molecular' @ 1171>\n",
      "<Token ' ' : 'biology' @ 1181>\n",
      "<Token '' : ',' @ 1188>\n",
      "<Token ' ' : 'department' @ 1190>\n",
      "<Token ' ' : 'of' @ 1201>\n",
      "<Token ' ' : 'integration' @ 1204>\n",
      "<Token ' ' : 'of' @ 1216>\n",
      "<Token ' ' : 'chinese' @ 1219>\n",
      "<Token ' ' : 'and' @ 1227>\n",
      "<Token ' ' : 'western' @ 1231>\n",
      "<Token ' ' : 'medicine' @ 1239>\n",
      "<Token '' : ',' @ 1247>\n",
      "<Token '\\n' : 'school' @ 1249>\n",
      "<Token ' ' : 'of' @ 1256>\n",
      "<Token ' ' : 'basic' @ 1259>\n",
      "<Token ' ' : 'medical' @ 1265>\n",
      "<Token ' ' : 'science' @ 1273>\n",
      "<Token '' : ',' @ 1280>\n",
      "<Token ' ' : 'peking' @ 1282>\n",
      "<Token ' ' : 'university' @ 1289>\n",
      "<Token '' : ',' @ 1299>\n",
      "<Token ' ' : 'beijing' @ 1301>\n",
      "<Token '' : ',' @ 1308>\n",
      "<Token ' ' : '100191' @ 1310>\n",
      "<Token '' : ',' @ 1316>\n",
      "<Token ' ' : 'china' @ 1318>\n",
      "<Token '' : '.' @ 1323>\n",
      "<Token '\\n' : 'cjbiochem@bjmu.edu.cn' @ 1325>\n",
      "<Token '' : '.' @ 1346>\n",
      "<Token '\\n\\n' : 'human' @ 1349>\n",
      "<Token ' ' : 'telomerase' @ 1355>\n",
      "<Token ' ' : 'rna' @ 1366>\n",
      "<Token ' ' : 'component' @ 1370>\n",
      "<Token ' ' : 'hterc' @ 1380>\n",
      "<Token ' ' : 'comprises' @ 1386>\n",
      "<Token ' ' : 'multiple' @ 1396>\n",
      "<Token ' ' : 'motifs' @ 1405>\n",
      "<Token ' ' : 'that' @ 1412>\n",
      "<Token ' ' : 'contribute' @ 1417>\n",
      "<Token ' ' : 'to' @ 1428>\n",
      "<Token '\\n' : 'hterc' @ 1431>\n",
      "<Token ' ' : 'biogenesis' @ 1437>\n",
      "<Token '' : ',' @ 1447>\n",
      "<Token ' ' : 'holoenzyme' @ 1449>\n",
      "<Token ' ' : 'activity' @ 1460>\n",
      "<Token '' : ',' @ 1468>\n",
      "<Token ' ' : 'and' @ 1470>\n",
      "<Token ' ' : 'enzyme' @ 1474>\n",
      "<Token ' ' : 'recruitment' @ 1481>\n",
      "<Token ' ' : 'to' @ 1493>\n",
      "<Token ' ' : 'telomeres' @ 1496>\n",
      "<Token '' : '.' @ 1505>\n",
      "<Token ' ' : 'hterc' @ 1507>\n",
      "<Token '\\n' : 'contains' @ 1513>\n",
      "<Token ' ' : 'several' @ 1522>\n",
      "<Token ' ' : 'guanine' @ 1530>\n",
      "<Token ' ' : 'tracts' @ 1538>\n",
      "<Token ' ' : '(' @ 1545>\n",
      "<Token '' : 'g' @ 1546>\n",
      "<Token '-' : 'tracts' @ 1548>\n",
      "<Token '' : ')' @ 1554>\n",
      "<Token ' ' : 'at' @ 1556>\n",
      "<Token ' ' : 'its' @ 1559>\n",
      "<Token ' ' : \"5'-end\" @ 1563>\n",
      "<Token '' : ',' @ 1569>\n",
      "<Token ' ' : 'but' @ 1571>\n",
      "<Token ' ' : 'its' @ 1575>\n",
      "<Token ' ' : 'associated' @ 1579>\n",
      "<Token '\\n' : 'proteins' @ 1590>\n",
      "<Token ' ' : 'and' @ 1599>\n",
      "<Token ' ' : 'potential' @ 1603>\n",
      "<Token ' ' : 'roles' @ 1613>\n",
      "<Token ' ' : 'in' @ 1619>\n",
      "<Token ' ' : 'telomerase' @ 1622>\n",
      "<Token ' ' : 'function' @ 1633>\n",
      "<Token ' ' : 'are' @ 1642>\n",
      "<Token ' ' : 'still' @ 1646>\n",
      "<Token ' ' : 'poorly' @ 1652>\n",
      "<Token ' ' : 'understood' @ 1659>\n",
      "<Token '' : '.' @ 1669>\n",
      "<Token ' \\n' : 'the' @ 1672>\n",
      "<Token ' ' : 'heterogeneous' @ 1676>\n",
      "<Token ' ' : 'nuclear' @ 1690>\n",
      "<Token ' ' : 'ribonucleoproteins' @ 1698>\n",
      "<Token ' ' : 'f' @ 1717>\n",
      "<Token '' : ',' @ 1718>\n",
      "<Token ' ' : 'h1' @ 1720>\n",
      "<Token '' : ',' @ 1722>\n",
      "<Token ' ' : 'and' @ 1724>\n",
      "<Token ' ' : 'h2' @ 1728>\n",
      "<Token ' ' : '(' @ 1731>\n",
      "<Token '' : 'hnrnp' @ 1732>\n",
      "<Token ' ' : 'f/h' @ 1738>\n",
      "<Token '' : ')' @ 1741>\n",
      "<Token ' ' : 'are' @ 1743>\n",
      "<Token '\\n' : 'splicing' @ 1747>\n",
      "<Token ' ' : 'factors' @ 1756>\n",
      "<Token ' ' : 'that' @ 1764>\n",
      "<Token ' ' : 'preferentially' @ 1769>\n",
      "<Token ' ' : 'bind' @ 1784>\n",
      "<Token ' ' : 'to' @ 1789>\n",
      "<Token ' ' : 'poly' @ 1792>\n",
      "<Token '' : '(' @ 1796>\n",
      "<Token '' : 'g' @ 1797>\n",
      "<Token '' : ')' @ 1798>\n",
      "<Token '' : '-rich' @ 1799>\n",
      "<Token ' ' : 'sequences' @ 1805>\n",
      "<Token ' ' : 'rna' @ 1815>\n",
      "<Token '' : '.' @ 1818>\n",
      "<Token ' ' : 'here' @ 1820>\n",
      "<Token '' : ',' @ 1824>\n",
      "<Token ' ' : 'we' @ 1826>\n",
      "<Token '\\n' : 'demonstrate' @ 1829>\n",
      "<Token ' ' : 'that' @ 1841>\n",
      "<Token ' ' : 'hnrnp' @ 1846>\n",
      "<Token ' ' : 'f/h' @ 1852>\n",
      "<Token ' ' : 'associate' @ 1856>\n",
      "<Token ' ' : 'with' @ 1866>\n",
      "<Token ' ' : 'both' @ 1871>\n",
      "<Token ' ' : 'hterc' @ 1876>\n",
      "<Token ' ' : 'and' @ 1882>\n",
      "<Token ' ' : 'telomerase' @ 1886>\n",
      "<Token ' ' : 'holoenzyme' @ 1897>\n",
      "<Token ' ' : 'to' @ 1908>\n",
      "<Token '\\n' : 'regulate' @ 1911>\n",
      "<Token ' ' : 'telomerase' @ 1920>\n",
      "<Token ' ' : 'activity' @ 1931>\n",
      "<Token '' : '.' @ 1939>\n",
      "<Token ' ' : 'we' @ 1941>\n",
      "<Token ' ' : 'reveal' @ 1944>\n",
      "<Token ' ' : 'hnrnp' @ 1951>\n",
      "<Token ' ' : 'f/h' @ 1957>\n",
      "<Token ' ' : 'bind' @ 1961>\n",
      "<Token ' ' : 'to' @ 1966>\n",
      "<Token ' ' : 'the' @ 1969>\n",
      "<Token ' ' : \"5'-end\" @ 1973>\n",
      "<Token ' ' : 'region' @ 1980>\n",
      "<Token ' ' : 'of' @ 1987>\n",
      "<Token '\\n' : 'hterc' @ 1990>\n",
      "<Token ' ' : 'in' @ 1996>\n",
      "<Token ' ' : 'vitro' @ 1999>\n",
      "<Token ' ' : 'and' @ 2005>\n",
      "<Token ' ' : 'in' @ 2009>\n",
      "<Token ' ' : 'vivo' @ 2012>\n",
      "<Token '' : ',' @ 2016>\n",
      "<Token ' ' : 'and' @ 2018>\n",
      "<Token ' ' : 'identify' @ 2022>\n",
      "<Token ' ' : 'the' @ 2031>\n",
      "<Token ' ' : 'first' @ 2035>\n",
      "<Token ' ' : 'three' @ 2041>\n",
      "<Token ' ' : 'g' @ 2047>\n",
      "<Token '-' : 'tracts' @ 2049>\n",
      "<Token ' ' : 'of' @ 2056>\n",
      "<Token ' ' : 'hterc' @ 2059>\n",
      "<Token ' ' : 'and' @ 2065>\n",
      "<Token '\\n' : 'qrrm1' @ 2069>\n",
      "<Token ' ' : 'domain' @ 2075>\n",
      "<Token ' ' : 'of' @ 2082>\n",
      "<Token ' ' : 'hnrnp' @ 2085>\n",
      "<Token ' ' : 'f/h' @ 2091>\n",
      "<Token ' ' : 'are' @ 2095>\n",
      "<Token ' ' : 'required' @ 2099>\n",
      "<Token ' ' : 'for' @ 2108>\n",
      "<Token ' ' : 'their' @ 2112>\n",
      "<Token ' ' : 'interaction' @ 2118>\n",
      "<Token '' : '.' @ 2129>\n",
      "<Token ' ' : 'furthermore' @ 2131>\n",
      "<Token '' : ',' @ 2142>\n",
      "<Token ' ' : 'hnrnp' @ 2144>\n",
      "<Token ' \\n' : 'f/h' @ 2151>\n",
      "<Token ' ' : 'also' @ 2155>\n",
      "<Token ' ' : 'directly' @ 2160>\n",
      "<Token ' ' : 'interact' @ 2169>\n",
      "<Token ' ' : 'with' @ 2178>\n",
      "<Token ' ' : 'telomerase' @ 2183>\n",
      "<Token ' ' : 'holoenzyme' @ 2194>\n",
      "<Token '' : '.' @ 2204>\n",
      "<Token ' ' : 'functionally' @ 2206>\n",
      "<Token '' : ',' @ 2218>\n",
      "<Token ' ' : 'we' @ 2220>\n",
      "<Token ' ' : 'show' @ 2223>\n",
      "<Token ' ' : 'that' @ 2228>\n",
      "<Token '\\n' : 'hnrnp' @ 2233>\n",
      "<Token ' ' : 'f/h' @ 2239>\n",
      "<Token ' ' : 'plays' @ 2243>\n",
      "<Token ' ' : 'important' @ 2249>\n",
      "<Token ' ' : 'roles' @ 2259>\n",
      "<Token ' ' : 'in' @ 2265>\n",
      "<Token ' ' : 'modulating' @ 2268>\n",
      "<Token ' ' : 'telomerase' @ 2279>\n",
      "<Token ' ' : 'activity' @ 2290>\n",
      "<Token ' ' : 'and' @ 2299>\n",
      "<Token ' ' : 'telomere' @ 2303>\n",
      "<Token '\\n' : 'length' @ 2312>\n",
      "<Token '' : '.' @ 2318>\n",
      "<Token ' ' : 'moreover' @ 2320>\n",
      "<Token '' : ',' @ 2328>\n",
      "<Token ' ' : 'hnrnp' @ 2330>\n",
      "<Token ' ' : 'f/h' @ 2336>\n",
      "<Token ' ' : 'deletion' @ 2340>\n",
      "<Token ' ' : 'greatly' @ 2349>\n",
      "<Token ' ' : 'impair' @ 2357>\n",
      "<Token ' ' : 'cancer' @ 2364>\n",
      "<Token ' ' : 'and' @ 2371>\n",
      "<Token ' ' : 'stem' @ 2375>\n",
      "<Token ' ' : 'cell' @ 2380>\n",
      "<Token '\\n' : 'proliferation' @ 2385>\n",
      "<Token '' : ',' @ 2398>\n",
      "<Token ' ' : 'and' @ 2400>\n",
      "<Token ' ' : 'induce' @ 2404>\n",
      "<Token ' ' : 'stem' @ 2411>\n",
      "<Token ' ' : 'cell' @ 2416>\n",
      "<Token ' ' : 'senescence' @ 2421>\n",
      "<Token '' : ',' @ 2431>\n",
      "<Token ' ' : 'while' @ 2433>\n",
      "<Token ' ' : 'hnrnp' @ 2439>\n",
      "<Token ' ' : 'f/h' @ 2445>\n",
      "<Token ' ' : 'overexpression' @ 2449>\n",
      "<Token '\\n' : 'delay' @ 2464>\n",
      "<Token ' ' : 'stem' @ 2470>\n",
      "<Token ' ' : 'cell' @ 2475>\n",
      "<Token ' ' : 'senescence' @ 2480>\n",
      "<Token '' : '.' @ 2490>\n",
      "<Token ' ' : 'collectively' @ 2492>\n",
      "<Token '' : ',' @ 2504>\n",
      "<Token ' ' : 'our' @ 2506>\n",
      "<Token ' ' : 'findings' @ 2510>\n",
      "<Token ' ' : 'unveil' @ 2519>\n",
      "<Token ' ' : 'a' @ 2526>\n",
      "<Token ' ' : 'novel' @ 2528>\n",
      "<Token ' ' : 'role' @ 2534>\n",
      "<Token ' ' : 'of' @ 2539>\n",
      "<Token '\\n' : 'hnrnp' @ 2542>\n",
      "<Token ' ' : 'f/h' @ 2548>\n",
      "<Token ' ' : 'as' @ 2552>\n",
      "<Token ' ' : 'the' @ 2555>\n",
      "<Token ' ' : 'binding' @ 2559>\n",
      "<Token ' ' : 'partners' @ 2567>\n",
      "<Token ' ' : 'of' @ 2576>\n",
      "<Token ' ' : 'hterc' @ 2579>\n",
      "<Token ' ' : 'and' @ 2585>\n",
      "<Token ' ' : 'telomerase' @ 2589>\n",
      "<Token ' ' : 'holoenzyme' @ 2600>\n",
      "<Token ' ' : 'to' @ 2611>\n",
      "<Token ' ' : 'regulate' @ 2614>\n",
      "<Token ' \\n' : 'telomerase' @ 2624>\n",
      "<Token ' ' : 'function' @ 2635>\n",
      "<Token '' : '.' @ 2643>\n",
      "<Token '\\n\\n' : 'doi' @ 2646>\n",
      "<Token '' : ':' @ 2649>\n",
      "<Token ' ' : '10.1038/s41418-019-0483-6' @ 2651>\n",
      "<Token ' \\n' : 'pmid' @ 2678>\n",
      "<Token '' : ':' @ 2682>\n",
      "<Token ' ' : '31863069' @ 2684>\n",
      "<Token ' \\n' : '' @ 2694>\n"
     ]
    }
   ],
   "source": [
    "#for more information about the individual tokens\n",
    "\n",
    "for token in tokenizer.tokenize(abstract):\n",
    "    print(repr(token))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
