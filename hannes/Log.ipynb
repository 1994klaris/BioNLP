{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worklog Hannes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Notes\n",
    "\n",
    "Began studying what had already been done on relation extraction, especially for medical texts: \n",
    "\n",
    "- [Training a Machine Learning Classifier for Relation Extraction from Medical Literature](https://www.microsoft.com/developerblog/2016/09/13/training-a-classifier-for-relation-extraction-from-medical-literature/)\n",
    "- [Distant supervision for relation extraction without labeled data](http://web.stanford.edu/~jurafsky/mintz.pdf)\n",
    "- [Relation Extraction Using Support Vector Machine](https://www.aclweb.org/anthology/I05-1033)\n",
    "- [Exploring Semi-supervised Variational Autoencoders for Biomedical Relation Extraction](https://arxiv.org/abs/1901.06103)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relations Model\n",
    "\n",
    "The idea of this model would be to take the extracted mentions in a section or a sentence along with parts of the text and identifying the relations/interactions if any. The approach to making a neural net for this is not as obvious and will probably take a bit more reading and hopefully I can find some implementation that isn't too complex for inspiration for the first solution. \n",
    "\n",
    "### Initial Model Design Suggestion\n",
    "\n",
    "Marcus gave some suggestions on how to approach building the relations extraction, simply put, using Keras: \n",
    "\n",
    "#### Network Design\n",
    "-  Input 1, Input 2\n",
    "-  Embeddings  [BioASQ](http://bioasq.org/news/bioasq-releases-continuous-space-word-vectors-obtained-applying-word2vec-pubmed-abstracts)\n",
    "-  BILSTM/Attention\n",
    "-  Concat (Merge layer)\n",
    "-  Dense (1 or more)\n",
    "\n",
    "Might use Spacy for POS and Dependency parsing. First models should just train for interaction vs. no interaction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019-04-15\n",
    "\n",
    "Missed the meeting because of chaotic trains. \n",
    "\n",
    "Relation extraction with SVM seems like a good approach with established performance with certain features. \n",
    "\n",
    "### Issues\n",
    "\n",
    "- The [TAC2018 DDI corpus](https://bionlp.nlm.nih.gov/tac2018druginteractions/) isn't really translateable to the problem we are trying to solve.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019-04-25\n",
    "\n",
    "Meeting with Anja, Pierre, Markus, Vilhelm and Olof:\n",
    "\n",
    "I've decided to abandon the TAC2018 [DDI corpus](https://bionlp.nlm.nih.gov/tac2018druginteractions/) and have started using the Binarized [Bio-Infer corpus](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-50) instead. I'm going to try to use [SciSpacy](https://allenai.github.io/scispacy/) for POS tagging. \n",
    "\n",
    "### BioInfer Interaction Tagging\n",
    "- Predicate Name (easiest to use for training and should be similar to training on no_interaction/causes/prevents)\n",
    "  - POS/NEG\n",
    "  - ACTION/POS(-/+/0)/NEG(-/+/0)\n",
    "  - Equality/Similarity/F-CONTAIN/MUTUALCOMPLEX/... (many many more)\n",
    "- Predicate MapsTo\n",
    "  - Assembly/Binding/Modification/Cleavage/...\n",
    "- Predicate Effect\n",
    "  - Other/Physical/Negative_Regulations/... (envelopes eachother: Unspecified_regulation -> Negative_regulation\n",
    " \n",
    "\n",
    "### Issues\n",
    "\n",
    "- The entity tagging in the BioInfer corpus uses multiple tokens for single entities (solved mostly by just merging those tokens for that interaction) and sometimes uses parts of subtokens for multiple entities (simply ignoring these cases makes the most sense since they basically cause one entity to have an interaction with itself). \n",
    "- Not sure how to use embeddings in a good way, getting help from Marcus. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-04-30\n",
    "\n",
    "Built the first working classifier for the BioInfer corpus running the [SGDClassifier](https://scikit-learn.org/stable/modules/sgd.html) using Sklearn. Using only entity distance and n-grams give ~70% accuracy for no_interaction/interaction, no_interaction/POS/NEG and ~35% accuracy for the third predicate part (Equality/Similarity/F-CONTAIN/MUTUALCOMPLEX/... (many many more)). The plan is to build the features: \n",
    "\n",
    "- n-gram\n",
    "- Distance\n",
    "- POS\n",
    "- Dependencies\n",
    "\n",
    "Test it on the [SGDClassifier](https://scikit-learn.org/stable/modules/sgd.html) and record the results then try switching to a Keras solution and adding embeddings. \n",
    "\n",
    "### Issues\n",
    "- SciSpacy/Spacy is not working on my current enviroment, will rebuild the enviroment and try to fix the issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-05-06\n",
    "\n",
    "Meeting in the BMC with the whole team. \n",
    "\n",
    "I presented my results from my initial scikit-learn classifier. The plan is to keep working with the code, make the pos extractions better and more reliable (some parsing changes really). Hopefully I can commit the Keras solution and embeddings after next weeks meeting. \n",
    "\n",
    "Spacy is working right now and hopefully switching to sciSpacy will work aswell and show a demonstrable improvement in accuracy. \n",
    "\n",
    "### Issues\n",
    "- Code needs a lot of cleanup and commenting, not sure when it will make sense for me to spend the time needed for this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-05-13\n",
    "Adjusted the code a lot, fixing sci-spacy, adding dependencies to the features, switched to using the regular SVC etc. Getting wrose results on the simpler classification (55%-65%) but slightly better on the harder classifications (45%). It changes way too much depending on how many negative examples it trains on which is annoying. I'm thinking of making a test set with way fewer negative examples while having more while training, will discuss at the meeting tomorrow. Been reading more about SVM settings: [in-depth-parameter-tuning-for-svc](https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc-758215394769)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-05-14\n",
    "\n",
    "Meeting in the BMC with the whole team. \n",
    "\n",
    "The entity tagging and relations training sets seem  to be coming along, it will get a little tight for me getting the training sets next week. Discussed some distinctions on how my relations ectractor will try to do. As I have not worked on entity tagging it will need sentences with entities tagged in some manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-05-17\n",
    "\n",
    "Built a Keras neural net model for the type of inputs discussed at the last meeting. It performs around 70% accuracy for: no_interaction, Positive, Negative on the bioInfer data. Currently it simply converts the two entities to \"ENTITY1\" and \"ENTITY2\" and trains on the processed sentences. \n",
    "\n",
    "I'm planning to introduce both stemming to the pre-processing and embeddnings to the net.\n",
    "\n",
    "### Issues\n",
    "- Still somewhat unsure on the detail on how to use Keras\n",
    "- Can't seem to \"overtrain\" the model on the training data no matter the batch and epoch sizes. Reaches 90% at best, which might be an issue with the data more than anythin, it's both small and arguably not the most consistent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-05-21\n",
    "Introduced 3-grams to the Keras model. It allows much more results on the training set, 30 epochs with batch size 20 gives the output: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "Training set: \n",
    "Accuracy: 0.9765\n",
    "Loss: 0.0121\n",
    "\n",
    "\n",
    "Test set: \n",
    "Accuracy: 0.7748\n",
    "Loss: 0.1310\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An improvement on both the trainingset learning rate (this is overtrained but it's good that you CAN overtrain the training set). \n",
    "\n",
    "Found a good source on word vector learning: [Distributed Representations of Sentences and Documents\n",
    "](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
