{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-4cd17935f97c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4cd17935f97c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <h1><center>Week 1</center></h1>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<h1><center>Week 1</center></h1>\n",
    "This week we got started with testing out BioBERT. We hade the choice of using 2 different versions of BioBERT; the standard BioBERT, available <a href = https://github.com/dmis-lab/biobert>here</a>, and NVIDIA's version that is optimized for running faster on their GPUs, available <a href = https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/LanguageModeling/BERT/biobert>here</a>. Due to misreading the documentation we thought the NVIDIA version required 16 GPUs to run, so we decided on beginning with the standard BioBERT.\n",
    "\n",
    "For future reference, the NVIDIA version is able to run on 1 GPU and we will probably be using their version in the future because their documentation is way better that the standard version.\n",
    "\n",
    "Anyways, to run the standard version of BioBERT one has to first download one of their pretrained models to fine tune, available <a href = https://github.com/naver/biobert-pretrained>here</a>. We selected the version 1.1 model since it was the newest. We then picked 3 datasets we wanted to test it on, one dataset for compounds, one for diseases and one for proteins. Since we were still unsure if we would be using NVIDIA's BioBERT or the standard one, we selected the 3 datasets that they both shared. They were called BC5CDR-chem, BC5CDR-disease and ChemProt.\n",
    "\n",
    "They datasets for compounds and diseases are available <a href = https://drive.google.com/file/d/1OletxmPYNkz2ltOr9pyT0b0iBtUWxslh/view>here</a> and the one for proteins can be found <a href = https://biocreative.bioinformatics.udel.edu/news/corpora/>here</a>. The protein dataset required a login, we created one with the username **biobert** and password **Kalleanka123**.\n",
    "\n",
    "We started with the compound dataset, BC5CDR-chem. First we tested it out on the test set with no fine-tuning and got these abysmal results:\n",
    "\n",
    "|                |               |\n",
    "| -------------- |---------------|\n",
    "| f-score        | 0.0011023806  |\n",
    "| precision      | 0.005602232   |\n",
    "| recall         | 0.43388188    |\n",
    "\n",
    "\n",
    "We then started the fine-tuning. This was done by using the command provided in their documentation. Since this was just a test, we ran it with most of the settings set to default. These are the default settings, we just altered the one to do with file locations.\n",
    "```\n",
    "python run_ner.py \\\n",
    "    --do_train=true \\\n",
    "    --do_eval=true \\\n",
    "    --vocab_file=$BIOBERT_DIR/vocab.txt \\\n",
    "    --bert_config_file=$BIOBERT_DIR/bert_config.json \\\n",
    "    --init_checkpoint=$BIOBERT_DIR/biobert_model.ckpt \\\n",
    "    --num_train_epochs=10.0 \\\n",
    "    --data_dir=$NER_DIR/ \\\n",
    "    --output_dir=/tmp/bioner/\n",
    "```\n",
    "The fine-tuning took **way** longer than we expected, we left the computer running for 22 hours and it only managed to finish 2 epochs. Luckily it generated checkpoints after every epoch, so we stopped it after 22 hours and evaluated the checkpoint from the 2nd epoch. This resulted in these results which were a lot more promising :\n",
    "\n",
    "|                |              |\n",
    "| -------------- |--------------|\n",
    "| f-score        | 0.785794     |\n",
    "| precision      | 0.73637426   |\n",
    "| recall         | 0.8526635    |\n",
    "\n",
    "Since we were fond of our computers and didn't feel like melting our CPUs we decided that we'd wait with further training until we got access to LUNARC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}